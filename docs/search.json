[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Rainie Xie Project Blog",
    "section": "",
    "text": "Welcome to my website…"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "My Resume",
    "section": "",
    "text": "Download PDF file."
  },
  {
    "objectID": "projects/project1/index.html",
    "href": "projects/project1/index.html",
    "title": "Homework 1",
    "section": "",
    "text": "text\n\ncommand+shift+i"
  },
  {
    "objectID": "projects/project1/index.html#sub-header",
    "href": "projects/project1/index.html#sub-header",
    "title": "Homework 1",
    "section": "",
    "text": "text\n\ncommand+shift+i"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "My Projects",
    "section": "",
    "text": "Homework 1\n\n\n\n\n\n\nRainie Xie\n\n\nApr 16, 2024\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "homeworks.html",
    "href": "homeworks.html",
    "title": "Marketing Analytics Assignment",
    "section": "",
    "text": "A Replication of Karlan and List (2007)\n\n\n\n\n\n\nRainie Xie\n\n\nApr 16, 2024\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "homeworks/hw1/hw1_questions.html",
    "href": "homeworks/hw1/hw1_questions.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nUsing direct mail solicitations to over 50,000 prior donors of a non-profit organization, the experiment tests how different matching grant offers affect the likelihood and amount of donations. The study finds that announcing a match offer significantly increases both the revenue per solicitation and the likelihood of receiving donations, but higher matching ratios ($2:$1, $3:$1) do not significantly boost donations compared to a $1:$1 ratio. The study also tested on heterogeneous treatment effects to observe the differences in political environments across different solicitees.\n\n\n\nParticipants: 50,083 prior donors to a liberal nonprofit organization.\n\nMethodology: Donors were randomly assigned to either a control group or one of several matching grant conditions, where their donations would be matched at different ratios. The control group received a standard donation request, while treatment groups received requests indicating that their donations would be matched by a leadership donor.\n\nVariables Tested:\n\nMatching ratios: $1:$1, $2:$1, and $3:$1.\n\nMaximum matching amounts: $25,000; $50,000; $100,000; unstated.\n\nSuggested donation amounts: based on the donor’s highest previous contribution, increased by 25% and 50%.\n\n\nOutcome Measures: Donation frequency (response rate) and amount donated (revenue per solicitation).\n\nImpact of Matching on Donations: Announcing a match increased donations by 19% and likelihood of donating by 22%.\n\nThis project seeks to replicate their results."
  },
  {
    "objectID": "homeworks/hw1/hw1_questions.html#introduction",
    "href": "homeworks/hw1/hw1_questions.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nUsing direct mail solicitations to over 50,000 prior donors of a non-profit organization, the experiment tests how different matching grant offers affect the likelihood and amount of donations. The study finds that announcing a match offer significantly increases both the revenue per solicitation and the likelihood of receiving donations, but higher matching ratios ($2:$1, $3:$1) do not significantly boost donations compared to a $1:$1 ratio. The study also tested on heterogeneous treatment effects to observe the differences in political environments across different solicitees.\n\n\n\nParticipants: 50,083 prior donors to a liberal nonprofit organization.\n\nMethodology: Donors were randomly assigned to either a control group or one of several matching grant conditions, where their donations would be matched at different ratios. The control group received a standard donation request, while treatment groups received requests indicating that their donations would be matched by a leadership donor.\n\nVariables Tested:\n\nMatching ratios: $1:$1, $2:$1, and $3:$1.\n\nMaximum matching amounts: $25,000; $50,000; $100,000; unstated.\n\nSuggested donation amounts: based on the donor’s highest previous contribution, increased by 25% and 50%.\n\n\nOutcome Measures: Donation frequency (response rate) and amount donated (revenue per solicitation).\n\nImpact of Matching on Donations: Announcing a match increased donations by 19% and likelihood of donating by 22%.\n\nThis project seeks to replicate their results."
  },
  {
    "objectID": "homeworks/hw1/hw1_questions.html#data",
    "href": "homeworks/hw1/hw1_questions.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nDescription\n\nimport pandas as pd \n\n# Load data \ndata = pd.read_stata('karlan_list_2007.dta')\n\ndata.describe(include='all')\n\n\n\n\n\n\n\n\n\ntreatment\ncontrol\nratio\nratio2\nratio3\nsize\nsize25\nsize50\nsize100\nsizeno\n...\nredcty\nbluecty\npwhite\npblack\npage18_39\nave_hh_sz\nmedian_hhincome\npowner\npsch_atlstba\npop_propurban\n\n\n\n\ncount\n50083.000000\n50083.000000\n50083\n50083.000000\n50083.000000\n50083\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n...\n49978.000000\n49978.000000\n48217.000000\n48047.000000\n48217.000000\n48221.000000\n48209.000000\n48214.000000\n48215.000000\n48217.000000\n\n\nunique\nNaN\nNaN\n4\nNaN\nNaN\n5\nNaN\nNaN\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\ntop\nNaN\nNaN\nControl\nNaN\nNaN\nControl\nNaN\nNaN\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\nfreq\nNaN\nNaN\n16687\nNaN\nNaN\n16687\nNaN\nNaN\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\nmean\n0.666813\n0.333187\nNaN\n0.222311\n0.222211\nNaN\n0.166723\n0.166623\n0.166723\n0.166743\n...\n0.510245\n0.488715\n0.819599\n0.086710\n0.321694\n2.429012\n54815.700533\n0.669418\n0.391661\n0.871968\n\n\nstd\n0.471357\n0.471357\nNaN\n0.415803\n0.415736\nNaN\n0.372732\n0.372643\n0.372732\n0.372750\n...\n0.499900\n0.499878\n0.168561\n0.135868\n0.103039\n0.378115\n22027.316665\n0.193405\n0.186599\n0.258654\n\n\nmin\n0.000000\n0.000000\nNaN\n0.000000\n0.000000\nNaN\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.000000\n0.000000\n0.009418\n0.000000\n0.000000\n0.000000\n5000.000000\n0.000000\n0.000000\n0.000000\n\n\n25%\n0.000000\n0.000000\nNaN\n0.000000\n0.000000\nNaN\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.000000\n0.000000\n0.755845\n0.014729\n0.258311\n2.210000\n39181.000000\n0.560222\n0.235647\n0.884929\n\n\n50%\n1.000000\n0.000000\nNaN\n0.000000\n0.000000\nNaN\n0.000000\n0.000000\n0.000000\n0.000000\n...\n1.000000\n0.000000\n0.872797\n0.036554\n0.305534\n2.440000\n50673.000000\n0.712296\n0.373744\n1.000000\n\n\n75%\n1.000000\n1.000000\nNaN\n0.000000\n0.000000\nNaN\n0.000000\n0.000000\n0.000000\n0.000000\n...\n1.000000\n1.000000\n0.938827\n0.090882\n0.369132\n2.660000\n66005.000000\n0.816798\n0.530036\n1.000000\n\n\nmax\n1.000000\n1.000000\nNaN\n1.000000\n1.000000\nNaN\n1.000000\n1.000000\n1.000000\n1.000000\n...\n1.000000\n1.000000\n1.000000\n0.989622\n0.997544\n5.270000\n200001.000000\n1.000000\n1.000000\n1.000000\n\n\n\n\n11 rows × 51 columns\n\n\n\n\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\nThe dataset consists of 50,083 observations and multiple columns that correspond to different variables within the study. The treatment group consists of 33,396 observations, and the control group consists of 16,687 observations. Note that the description includes both numerical and categorical data, with some summary statistics such as count, unique, top (most common value), and frequency for categorical data, and count, mean, etc., for numerical data.\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\n\nfrom scipy import stats\nimport statsmodels.api as sm \n\n# First, we'll perform a t-test for the 'mrm2' variable\n# 'mrm2' stands for the number of months since last donation\n\ntreatment_group = data[data['treatment'] == 1]['mrm2'].dropna()\ncontrol_group = data[data['treatment'] == 0]['mrm2'].dropna()\n\n# Perform the t-test\nt_test_result = stats.ttest_ind(treatment_group, control_group, equal_var=False)\n\n# Then, run a linear regression for the 'mrm2' variable \nX = sm.add_constant(data['treatment'])\ny = data['mrm2'] \n\n# Perform the linear regression\nmodel = sm.OLS(y, X, missing='drop').fit()\n\n# Print the results \nprint(t_test_result)\nprint(model.summary()) \n\nTtestResult(statistic=0.11953155228177251, pvalue=0.9048549631450832, df=33394.47581389535)\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   mrm2   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                 -0.000\nMethod:                 Least Squares   F-statistic:                   0.01428\nDate:                Tue, 16 Apr 2024   Prob (F-statistic):              0.905\nTime:                        22:55:14   Log-Likelihood:            -1.9585e+05\nNo. Observations:               50082   AIC:                         3.917e+05\nDf Residuals:                   50080   BIC:                         3.917e+05\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst         12.9981      0.094    138.979      0.000      12.815      13.181\ntreatment      0.0137      0.115      0.119      0.905      -0.211       0.238\n==============================================================================\nOmnibus:                     8031.352   Durbin-Watson:                   2.004\nProb(Omnibus):                  0.000   Jarque-Bera (JB):            12471.135\nSkew:                           1.163   Prob(JB):                         0.00\nKurtosis:                       3.751   Cond. No.                         3.23\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\nResult forboth the t-test and the linear regression for the variable ‘mrm2’ (months since last donation) are consistent:\n\nT-test: The t-statistic is approximately 0.119, with a p-value of about 0.905. This indicates that there is no statistically significant difference in the mean number of months since last donation between the treatment and control groups at the 95% confidence level.\n\nLinear Regression: The regression coefficient for the ‘treatment’ variable is approximately 0.0137 with a standard error of about 0.115. The p-value for this coefficient is about 0.905, which also indicates that there is no statistically significant difference between the treatment and control groups.\n\n\n\n\n\n\n\nMore Tests for the Randomization Mechanism\n\n\n\n\n\n\n# Let's conduct similar balance tests for other variables. \n\n# Perform a t-test for the 'female' variable\ntreatment_group_female = data[data['treatment'] == 1]['female'].dropna()\ncontrol_group_female = data[data['treatment'] == 0]['female'].dropna()\n\n# Perform the t-test\nt_test_result_female = stats.ttest_ind(treatment_group_female, control_group_female)\n\n# Linear regression for 'female' on 'treatment'\nX_female = sm.add_constant(data['treatment'])\ny_female = data['female'] \n\n# Perform the linear regression\nmodel_female = sm.OLS(y_female, X_female, missing='drop').fit()\n\n# Print the results \nprint(t_test_result_female)\nprint(model_female.summary()) \n\n# Perform a t-test for Highest previous contribution the 'hpa' variable\ntreatment_group_hpa = data[data['treatment'] == 1]['hpa'].dropna()\ncontrol_group_hpa = data[data['treatment'] == 0]['hpa'].dropna()\n\n# Perform the t-test\nt_test_result_hpa = stats.ttest_ind(treatment_group_hpa, control_group_hpa)\n\n# Linear regression for 'female' on 'treatment'\nX_hpa = sm.add_constant(data['treatment'])\ny_hpa = data['hpa'] \n\n# Perform the linear regression\nmodel_hpa = sm.OLS(y_hpa, X_hpa, missing='drop').fit()\n\n# Print the results \nprint(t_test_result_hpa)\nprint(model_hpa.summary()) \n\nTtestResult(statistic=-1.7583691871450704, pvalue=0.07869095826986476, df=48970.0)\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                 female   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                  0.000\nMethod:                 Least Squares   F-statistic:                     3.092\nDate:                Tue, 16 Apr 2024   Prob (F-statistic):             0.0787\nTime:                        22:55:14   Log-Likelihood:                -30148.\nNo. Observations:               48972   AIC:                         6.030e+04\nDf Residuals:                   48970   BIC:                         6.032e+04\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst          0.2827      0.004     80.688      0.000       0.276       0.290\ntreatment     -0.0075      0.004     -1.758      0.079      -0.016       0.001\n==============================================================================\nOmnibus:                    17873.494   Durbin-Watson:                   2.004\nProb(Omnibus):                  0.000   Jarque-Bera (JB):            10142.985\nSkew:                           0.993   Prob(JB):                         0.00\nKurtosis:                       1.986   Cond. No.                         3.22\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\nTtestResult(statistic=0.944145044786662, pvalue=0.34510008823759086, df=50081.0)\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                    hpa   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                 -0.000\nMethod:                 Least Squares   F-statistic:                    0.8924\nDate:                Tue, 16 Apr 2024   Prob (F-statistic):              0.345\nTime:                        22:55:14   Log-Likelihood:            -2.8468e+05\nNo. Observations:               50083   AIC:                         5.694e+05\nDf Residuals:                   50081   BIC:                         5.694e+05\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst         58.9602      0.551    107.005      0.000      57.880      60.040\ntreatment      0.6371      0.675      0.944      0.345      -0.685       1.960\n==============================================================================\nOmnibus:                    66199.149   Durbin-Watson:                   2.003\nProb(Omnibus):                  0.000   Jarque-Bera (JB):         14448195.271\nSkew:                           7.552   Prob(JB):                         0.00\nKurtosis:                      84.826   Cond. No.                         3.23\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\n\n\n\nThe results for both the t-test and the linear regression for the variables ‘female’ and ‘hpa’ are consistent similar to the ‘mrm2’, indicating that the treatment and control groups are not significantly different at the 95% confidence level. Based on these 3 tests, it supports the notion that the treatment and control groups are balanced with respect to the randomization mechanism. Refer to the Table 1 on the paper, the treatment and control groups are quite similar in mean and standar deviation across all the variables listed, suggesting good balance."
  },
  {
    "objectID": "homeworks/hw1/hw1_questions.html#experimental-results",
    "href": "homeworks/hw1/hw1_questions.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\n\nBarplot with proportion of people who donated.\n\nimport matplotlib.pyplot as plt\n\n# Calculate the proportion of people who donated in both treatment and control groups\nprop_donated_treatment = data[data['treatment'] == 1]['gave'].mean()\nprop_donated_control = data[data['treatment'] == 0]['gave'].mean()\n\n# Data to plot\nproportions = [prop_donated_treatment, prop_donated_control]\nbar_labels = ['Treatment', 'Control']\n\n# Create the barplot\nplt.figure(figsize=(10, 6))\nplt.bar(bar_labels, proportions, color=['blue', 'orange'])\n\n# Title and labels\nplt.title('Proportion of People Who Donated by Group')\nplt.ylabel('Proportion of People')\nplt.xlabel('Group')\n\n# Show the plot\nplt.show()\n\n\n\n\n\n\n\n\nNote: Results from this barplot are consistent with the results in Table 2a Panel A.\n\n\n\nT-test & Linear Regression on Charitable Contribution\n\n# T-test for 'gave' variable\ntreatment_gave = data[data['treatment'] == 1]['gave'].dropna()\ncontrol_gave = data[data['treatment'] == 0]['gave'].dropna()\nt_test_result_gave = stats.ttest_ind(treatment_gave, control_gave)\n\n# Bivariate linear regression: regressing 'gave' on 'treatment'\nX_donation = sm.add_constant(data['treatment'])\ny_donation = data['gave']\n\n# Regression model\ndonation_model = sm.OLS(y_donation, X_donation, missing='drop').fit()\n\n# Print results \nprint(t_test_result_gave) \nprint(donation_model.summary())\n\nTtestResult(statistic=3.101361000543946, pvalue=0.0019274025949016982, df=50081.0)\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   gave   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                  0.000\nMethod:                 Least Squares   F-statistic:                     9.618\nDate:                Tue, 16 Apr 2024   Prob (F-statistic):            0.00193\nTime:                        22:55:15   Log-Likelihood:                 26630.\nNo. Observations:               50083   AIC:                        -5.326e+04\nDf Residuals:                   50081   BIC:                        -5.324e+04\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst          0.0179      0.001     16.225      0.000       0.016       0.020\ntreatment      0.0042      0.001      3.101      0.002       0.002       0.007\n==============================================================================\nOmnibus:                    59814.280   Durbin-Watson:                   2.005\nProb(Omnibus):                  0.000   Jarque-Bera (JB):          4317152.727\nSkew:                           6.740   Prob(JB):                         0.00\nKurtosis:                      46.440   Cond. No.                         3.23\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\nResults:\n1. T-test Results: The t-statistic is 3.101 with a p-value of approximately 0.0019. Since the p-value is less than 0.05, this suggests that there is a statistically significant difference in the likelihood of making a donation between the treatment and control groups. This means that those in the treatment group (who received the matched donations letter) were significantly more likely to donate than those in the control group (who received a standard donation request).\n2. Linear Regression Results: The regression coefficient for the treatment variable is 0.0042 with a standard error of 0.001. The t-statistic for the treatment variable is also 3.101, which corresponds with the t-test result, and the p-value is 0.002, confirming the finding from the t-test. This indicates a statistically significant effect of the treatment on the likelihood of giving a donation. Since the dependent variable gave is binary, this coefficient can be interpreted as the difference in the probability of giving between the treatment and control groups.\nThe consistency between the t-test and regression analysis reinforces the validity of the findings. The practical interpretation is that being in the treatment group (i.e., receiving a matched donation solicitation) is associated with a higher likelihood of donating compared to being in the control group. This provides evidence that the match donation strategy employed is effective in increasing the rate of charitable contributions.\nThese results tell us about human behavior regarding incentives and charitable giving. Specifically, they suggest that potential donors are more likely to contribute when they feel their donation has a larger impact, which is implied by the matching of their donations.\n\n\nProbit Model on Charitable Contribution\n\nfrom statsmodels.discrete.discrete_model import Probit\n\n# Preparing the data for the Probit model\nX_probit = sm.add_constant(data['treatment'])\ny_probit = data['gave']\n\n# Fit the Probit model\nprobit_model = Probit(y_probit, X_probit).fit()\n\n# Display the summary of the model\nprint(probit_model.summary())\n\nOptimization terminated successfully.\n         Current function value: 0.100443\n         Iterations 7\n                          Probit Regression Results                           \n==============================================================================\nDep. Variable:                   gave   No. Observations:                50083\nModel:                         Probit   Df Residuals:                    50081\nMethod:                           MLE   Df Model:                            1\nDate:                Tue, 16 Apr 2024   Pseudo R-squ.:               0.0009783\nTime:                        22:55:15   Log-Likelihood:                -5030.5\nconverged:                       True   LL-Null:                       -5035.4\nCovariance Type:            nonrobust   LLR p-value:                  0.001696\n==============================================================================\n                 coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst         -2.1001      0.023    -90.073      0.000      -2.146      -2.054\ntreatment      0.0868      0.028      3.113      0.002       0.032       0.141\n==============================================================================\n\n\nThe coefficient for the treatment variable is 0.0868, with a standard error of 0.028. The z-statistic for the treatment effect is 3.113, with a corresponding p-value of 0.002. These results indicate that the effect of treatment on the probability of making a donation is positive and statistically significant at the 1% level (since the p-value is below 0.01). This means that being in the treatment group makes a statistically significant increase in the likelihood of donating compared to the control group, holding other factors constant.\nIn the context of the experiment, this finding tells us that the treatment (which likely involves receiving a matched donation offer) is effective in increasing the propensity to give among the recipients of the fundraising letters.\nHowever, the coefficient is different from the one reported in Table 3, while the result from previous OLS regression matched with Table 3. Need further analysis.\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate. :::: {.callout-note collapse=“true”} ### T-tests between different match ratios\n\n# Subset the data based on match ratio\ndata_1to1 = data[data['ratio'] == 1]['gave']\ndata_2to1 = data[data['ratio2'] == 1]['gave']\ndata_3to1 = data[data['ratio3'] == 1]['gave']\n\n# Perform t-tests between the different match ratios\nttest_results_1to1_vs_2to1 = stats.ttest_ind(data_1to1.dropna(), data_2to1.dropna())\nttest_results_1to1_vs_3to1 = stats.ttest_ind(data_1to1.dropna(), data_3to1.dropna())\nttest_results_2to1_vs_3to1 = stats.ttest_ind(data_2to1.dropna(), data_3to1.dropna())\n\n# Print results\nprint(\"1:1 vs 2:1 Match Ratio:\", ttest_results_1to1_vs_2to1)\nprint(\"1:1 vs 3:1 Match Ratio:\", ttest_results_1to1_vs_3to1)\nprint(\"2:1 vs 3:1 Match Ratio:\", ttest_results_2to1_vs_3to1)\n\n1:1 vs 2:1 Match Ratio: TtestResult(statistic=-0.96504713432247, pvalue=0.33453168549723933, df=22265.0)\n1:1 vs 3:1 Match Ratio: TtestResult(statistic=-1.0150255853798622, pvalue=0.31010466370866724, df=22260.0)\n2:1 vs 3:1 Match Ratio: TtestResult(statistic=-0.05011583793874515, pvalue=0.9600305283739325, df=22261.0)\n\n\n::::\nThese results with high p-values indicate that the match ratios are not significantly different from each other, statistically the size of the match ratio did not significantly affeect whether people donate or not. This finding would support the authors’ suggestion that increasing the match ratio from 1:1 to 2:1 or 3:1 does not seem to increase the likelihood of someone donating.\n\n\n\n\n\n\nRegression on different match ratios\n\n\n\n\n\n\n# Create the variable 'ratio1' \ndata['ratio1'] = (data['ratio'] == 1).astype(int)\n\n# Create the regression model\nX = sm.add_constant(data[['ratio1', 'ratio2', 'ratio3']])\ny = data['gave']\n# Fit the regression model\nregression_model_ratio = sm.OLS(y, X, missing='drop').fit()\n\n# Output the summary of the model\nprint(regression_model_ratio.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   gave   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                  0.000\nMethod:                 Least Squares   F-statistic:                     3.665\nDate:                Tue, 16 Apr 2024   Prob (F-statistic):             0.0118\nTime:                        22:55:15   Log-Likelihood:                 26630.\nNo. Observations:               50083   AIC:                        -5.325e+04\nDf Residuals:                   50079   BIC:                        -5.322e+04\nDf Model:                           3                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst          0.0179      0.001     16.225      0.000       0.016       0.020\nratio1         0.0029      0.002      1.661      0.097      -0.001       0.006\nratio2         0.0048      0.002      2.744      0.006       0.001       0.008\nratio3         0.0049      0.002      2.802      0.005       0.001       0.008\n==============================================================================\nOmnibus:                    59812.754   Durbin-Watson:                   2.005\nProb(Omnibus):                  0.000   Jarque-Bera (JB):          4316693.217\nSkew:                           6.740   Prob(JB):                         0.00\nKurtosis:                      46.438   Cond. No.                         4.26\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\n\n\n\nBased on the regression output:\n‘ratio1’: The coefficient for the 1:1 match ratio is 0.0029 with a p-value of 0.097. This suggests that the effect of the 1:1 match ratio on the likelihood of donating is not statistically significant at the 0.05 level. The coefficient indicates a small increase in the probability of giving compared to the baseline category, but this result is not statistically robust. ‘ratio2’: The coefficient for ratio2 (0.0048) is statistically significant (p &lt; 0.05), which indicates that there is a significant difference in the likelihood of donating between the 2:1 match and the baseline, with a 0.48 percentage point increase. ‘ratio3’: The coefficient for ratio3 (0.0049) is also statistically significant (p &lt; 0.05), suggesting a 0.49 percentage point increase in the likelihood of donating for the 3:1 match.\n\n\n\n\n\n\nResponse Rate Difference\n\n\n\n\n\n\n# Calculating response rates directly from the data\nmean_response_1to1 = data[data['ratio1'] == 1]['gave'].mean()\nmean_response_2to1 = data[data['ratio2'] == 1]['gave'].mean()\nmean_response_3to1 = data[data['ratio3'] == 1]['gave'].mean()\n\n# Calculating the differences in response rates\ndiff_response_1to1_vs_2to1 = mean_response_2to1 - mean_response_1to1\ndiff_response_2to1_vs_3to1 = mean_response_3to1 - mean_response_2to1\n\n# Now calculate the differences using the regression coefficients\ncoef_1to1 = regression_model_ratio.params['ratio1']\ncoef_2to1 = regression_model_ratio.params['ratio2']\ncoef_3to1 = regression_model_ratio.params['ratio3']\n\ndiff_coef_1to1_vs_2to1 = coef_2to1 - coef_1to1\ndiff_coef_2to1_vs_3to1 = coef_3to1 - coef_2to1\n\nprint(\"Directly from data:\")\nprint(\"1:1 vs 2:1 Match Ratio Response Rate Difference:\", diff_response_1to1_vs_2to1)\nprint(\"2:1 vs 3:1 Match Ratio Response Rate Difference:\", diff_response_2to1_vs_3to1)\n\nprint(\"\\nFrom regression coefficients:\")\nprint(\"1:1 vs 2:1 Match Ratio Coefficient Difference:\", diff_coef_1to1_vs_2to1)\nprint(\"2:1 vs 3:1 Match Ratio Coefficient Difference:\", diff_coef_2to1_vs_3to1)\n\nDirectly from data:\n1:1 vs 2:1 Match Ratio Response Rate Difference: 0.0018842510217149944\n2:1 vs 3:1 Match Ratio Response Rate Difference: 0.00010002398025293902\n\nFrom regression coefficients:\n1:1 vs 2:1 Match Ratio Coefficient Difference: 0.0018842510217149796\n2:1 vs 3:1 Match Ratio Coefficient Difference: 0.00010002398025295116\n\n\n\n\n\nBased on the results provided, both the direct data calculation and the regression coefficients yield very similar findings:\n\nThe difference in response rate between the 1:1 and 2:1 match ratios is approximately 0.1884 percentage points.\n\nThe difference in response rate between the 2:1 and 3:1 match ratios is approximately 0.0100 percentage points.\nThese differences are quite small, indicating that while there is a slight increase in the likelihood of donating when moving from a 1:1 to a 2:1 match ratio, the further increase from a 2:1 to a 3:1 match ratio is even smaller and practically negligible.\n\nConclusions regarding the effectiveness of different sizes of matched donations:\n1:1 vs 2:1 Match Ratio: There is a small but potentially meaningful increase in donation likelihood when the match ratio is increased from 1:1 to 2:1. This suggests that donors may be somewhat responsive to a more generous match offer, though the effect is not large.\n2:1 vs 3:1 Match Ratio: The extremely small increase when moving from a 2:1 to a 3:1 match ratio suggests that there is very little to gain in donation likelihood by offering a more generous match beyond 2:1. This increment is so small that it is likely to be of limited practical significance.\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\n\nT-test on Donation Amount\n\n# Separate the donation amounts by treatment status\ntreatment_amounts = data[data['treatment'] == 1]['amount']\ncontrol_amounts = data[data['treatment'] == 0]['amount']\n\n# Perform the t-test\nt_test_results = stats.ttest_ind(treatment_amounts.dropna(), control_amounts.dropna())\n\n# Print the t-test results\nprint(t_test_results)\n\nTtestResult(statistic=1.8605020225753781, pvalue=0.06282038947470686, df=50081.0)\n\n\nSince the p-value is greater than 0.05, there is not enough evidence to reject the null hypothesis that there is no difference in the average donation amount between the treatment and control groups.\nEffect Size: The positive t-statistic indicates that the treatment group’s mean donation amount is higher than that of the control group, but since the p-value is not below 0.05, this difference is not statistically significant.\nIt’s important to consider the practical significance. Given the p-value is relatively close to 0.05, it may also be worthwhile to look at other factors or conduct further research.\n\n\nRegression on Donation Amount with people who donated\n\n# Filter the dataset for only those individuals who made a donation\ndonor_data = data[data['gave'] == 1]\n\nX = sm.add_constant(donor_data['treatment'])\n\ny = donor_data['amount']\n\n# Fit the regression model for this subset of donors\nregression_model_donor = sm.OLS(y, X, missing='drop').fit()\n\n# Output the summary of the model\nprint(regression_model_donor.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                 amount   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                 -0.001\nMethod:                 Least Squares   F-statistic:                    0.3374\nDate:                Tue, 16 Apr 2024   Prob (F-statistic):              0.561\nTime:                        22:55:15   Log-Likelihood:                -5326.8\nNo. Observations:                1034   AIC:                         1.066e+04\nDf Residuals:                    1032   BIC:                         1.067e+04\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst         45.5403      2.423     18.792      0.000      40.785      50.296\ntreatment     -1.6684      2.872     -0.581      0.561      -7.305       3.968\n==============================================================================\nOmnibus:                      587.258   Durbin-Watson:                   2.031\nProb(Omnibus):                  0.000   Jarque-Bera (JB):             5623.279\nSkew:                           2.464   Prob(JB):                         0.00\nKurtosis:                      13.307   Cond. No.                         3.49\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\nThe treatment coefficient is -1.6684 with a p-value of 0.561, which is not statistically significant at the conventional 0.05 level. This indicates that the treatment does not have a statistically significant impact on the donation amount for those who chose to donate.\nThe lack of significance of the treatment coefficient suggests that there is no strong evidence that the treatment (such as being offered a matched donation) significantly influences the amount donated by those who decided to donate. Even though the treatment was randomly assigned, the lack of statistical significance in this context means we cannot conclusively say that there is a causal effect of the treatment on the amount donated. From this analysis, we learn that while the treatment might influence the decision to donate in the first place, among those who do decide to donate, the treatment doesn’t significantly affect the amount they choose to donate. This could indicate that other factors may play a more crucial role in determining the size of the donation once the decision to donate has been made.\n\n\n\n\n\n\nHistogram of Donation Amount for those who donated\n\n\n\n\n\n\n# Separate the donation amounts by treatment status\ntreatment_donations = donor_data[donor_data['treatment'] == 1]['amount']\ncontrol_donations = donor_data[donor_data['treatment'] == 0]['amount']\n\n# Calculate the sample averages\navg_treatment_donations = treatment_donations.mean()\navg_control_donations = control_donations.mean()\n\n# Create histogram for the treatment group\nplt.figure(figsize=(14, 7))\n\n# Treatment group plot\nplt.subplot(1, 2, 1)\nplt.hist(treatment_donations, bins=30, color='blue', alpha=0.7)\nplt.axvline(avg_treatment_donations, color='red', linestyle='dashed', linewidth=2)\nplt.title('Treatment Group Donations')\nplt.xlabel('Donation Amount')\nplt.ylabel('Frequency')\nplt.annotate('Average: ${:.2f}'.format(avg_treatment_donations), \n             xy=(avg_treatment_donations, 5), \n             xytext=(avg_treatment_donations, 10),\n             arrowprops=dict(facecolor='red', shrink=0.05))\n\n# Control group plot\nplt.subplot(1, 2, 2)\nplt.hist(control_donations, bins=30, color='green', alpha=0.7)\nplt.axvline(avg_control_donations, color='red', linestyle='dashed', linewidth=2)\nplt.title('Control Group Donations')\nplt.xlabel('Donation Amount')\nplt.ylabel('Frequency')\nplt.annotate('Average: ${:.2f}'.format(avg_control_donations), \n             xy=(avg_control_donations, 5), \n             xytext=(avg_control_donations, 10),\n             arrowprops=dict(facecolor='red', shrink=0.05))\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "homeworks/hw1/hw1_questions.html#simulation-experiment",
    "href": "homeworks/hw1/hw1_questions.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\n\nimport numpy as np \n# Parameters for the simulation\ntrue_p_control = 0.018  # The true probability for the control group\ntrue_p_treatment = 0.022  # The true probability for the treatment group\nn_simulations = 10000\n\n# Simulate 100,000 draws from the control distribution \ncontrol_draws = np.random.binomial(1, true_p_control, 100000)\n\n# Simulate 10,000 draws from the treatment distribution \ntreatment_draws = np.random.binomial(1, true_p_treatment, 10000)\n\n# Calculate the cumulative average of donations for control and treatment\ncumulative_avg_control = np.cumsum(control_draws) / np.arange(1, 100001)\ncumulative_avg_treatment = np.cumsum(treatment_draws) / np.arange(1, 10001)\n\n# Calculate a vector of 10,000 differences between treatment and control cumulative averages\n# Since the control has more observations, slice it to match the treatment's size\ndifferences = cumulative_avg_treatment - cumulative_avg_control[:10000]\n\n# Plot the cumulative average of the vector of differences\nplt.figure(figsize=(14, 7))\nplt.plot(differences, label='Cumulative Average of Differences')\nplt.hlines(true_p_treatment - true_p_control, xmin=0, xmax=n_simulations, color='red', linestyles='dashed', label='True Difference')\nplt.legend()\nplt.title('Cumulative Average of Differences Between Treatment and Control')\nplt.xlabel('Number of Simulations')\nplt.ylabel('Cumulative Average of Donation Probability Difference')\nplt.ylim(-0.1, 0.01)\nplt.show()\n\n\n\n\n\n\n\n\nThe blue line represents the cumulative average of the differences between the treatment and control groups across the simulations.\nThe dashed red line represents the true difference in probabilities between the treatment and control groups, which is 0.004 (from p=0.022 for treatment minus p=0.018 for control).\nAfter initial volatility due to the small sample size, the blue line starts to stabilize and converge toward the dashed red line, which is the expected behavior according to the Law of Large Numbers. As the number of simulations increases, the cumulative average difference becomes less variable and fluctuates around the true difference of 0.004. The simulation confirms the Law of Large Numbers, as the cumulative average difference approaches the true difference with a large enough number of simulations. This demonstrates that with a sufficiently large sample size, the sample mean will provide a good estimate of the population mean.\n\n\nCentral Limit Theorem\n\n# Parameters for the simulation\nn_draws_list = [50, 200, 500, 1000]\nn_replications = 1000\navg_diffs = {}\n\n# Function to perform simulation for different sample sizes\ndef simulate_diffs(n, replications, p_control, p_treatment):\n    diffs = []\n    for _ in range(replications):\n        control_sample = np.random.binomial(1, p_control, n)\n        treatment_sample = np.random.binomial(1, p_treatment, n)\n        diffs.append(treatment_sample.mean() - control_sample.mean())\n    return diffs\n\n# Run simulations for each sample size\nfor n_draws in n_draws_list:\n    avg_diffs[n_draws] = simulate_diffs(n_draws, n_replications, true_p_control, true_p_treatment)\n\n# Create histograms\nplt.figure(figsize=(16, 8))\nfor i, n_draws in enumerate(n_draws_list, 1):\n    plt.subplot(2, 2, i)\n    plt.hist(avg_diffs[n_draws], bins=30, color='skyblue', edgecolor='black')\n    plt.axvline(x=0, color='red', linestyle='dashed', linewidth=2)\n    plt.title(f'Histogram of 1000 Sample Averages at N={n_draws}')\n    plt.xlabel('Average Difference')\n    plt.ylabel('Frequency')\n    plt.axvline(true_p_treatment - true_p_control, color='green', linestyle='dashed', linewidth=2, label='True Difference')\n\nplt.show()\n\n\n\n\n\n\n\n\nEach histogram represents the distribution of 1000 sample averages, calculated by taking 50, 200, 500, and 1000 draws from both the control and treatment distributions and finding the average difference between those draws. The vertical dashed red line indicates zero difference, while the vertical dashed green line indicates the true difference in the population.\n\nHistogram at N=50: This histogram shows a wide spread of the sample averages, with a considerable variance around zero. The true difference seems to be in the middle of the distribution, suggesting that when you take small sample sizes, the sample mean can vary significantly.\n\nHistogram at N=200: As the sample size increases to 200, the histogram starts to take on a more bell-shaped curve, indicating the beginning of normal distribution in accordance with the Central Limit Theorem. Zero is still around the center of the distribution, and the variance is decreasing.\n\nHistogram at N=500: With a sample size of 500, the distribution of the sample averages becomes tighter and more symmetric around the true difference, showing less uncertainty and further confirmation of the Central Limit Theorem.\n\nHistogram at N=1000: At this sample size, the histogram clearly shows a normal distribution around the true difference, and zero is not in the tail of the distribution. The average differences are centering more closely around the true difference."
  },
  {
    "objectID": "homeworks/hw1/hw1_questions.html#results",
    "href": "homeworks/hw1/hw1_questions.html#results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Results:",
    "text": "Results:\ntodo: run a probit regression where the outcome variable is whether any charitable donation was made and the explanatory variable is assignment to treatment or control. Confirm that your results replicate Table 3 column 1 in the paper.\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\ntodo: Use a series of t-tests to test whether the size of the match ratio has an effect on whether people donate or not. For example, does the 2:1 match rate lead increase the likelihood that someone donates as compared to the 1:1 match rate? Do your results support the “figures suggest” comment the authors make on page 8?\ntodo: Assess the same issue using a regression. Specifically, create the variable ratio1 then regress gave on ratio1, ratio2, and ratio3 (or alternatively, regress gave on the categorical variable ratio). Interpret the coefficients and their statistical precision.\ntodo: Calculate the response rate difference between the 1:1 and 2:1 match ratios and the 2:1 and 3:1 ratios. Do this directly from the data, and do it by computing the differences in the fitted coefficients of the previous regression. what do you conclude regarding the effectiveness of different sizes of matched donations?\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\ntodo: Calculate a t-test or run a bivariate linear regression of the donation amount on the treatment status. What do we learn from doing this analysis?\ntodo: now limit the data to just people who made a donation and repeat the previous analysis. This regression allows you to analyze how much respondents donate conditional on donating some positive amount. Interpret the regression coefficients – what did we learn? Does the treatment coefficient have a causal interpretation?\ntodo: Make two plot: one for the treatment group and one for the control. Each plot should be a histogram of the donation amounts only among people who donated. Add a red vertical bar or some other annotation to indicate the sample average for each plot."
  }
]