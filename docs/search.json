[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Rainie Xie Project Blog",
    "section": "",
    "text": "Welcome to my website…"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "My Resume",
    "section": "",
    "text": "Download PDF file."
  },
  {
    "objectID": "projects/project1/index.html",
    "href": "projects/project1/index.html",
    "title": "Homework 1",
    "section": "",
    "text": "text\n\ncommand+shift+i"
  },
  {
    "objectID": "projects/project1/index.html#sub-header",
    "href": "projects/project1/index.html#sub-header",
    "title": "Homework 1",
    "section": "",
    "text": "text\n\ncommand+shift+i"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "My Projects",
    "section": "",
    "text": "Homework 1\n\n\n\n\n\n\nRainie Xie\n\n\nApr 16, 2024\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "homeworks.html",
    "href": "homeworks.html",
    "title": "Marketing Analytics Assignment",
    "section": "",
    "text": "Poisson Regression Examples\n\n\n\n\n\n\nRainie Xie\n\n\nMay 29, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nKey Drivers Analysis\n\n\n\n\n\n\nRainie Xie\n\n\nMay 29, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nMultinomial logit (MNL) models\n\n\n\n\n\n\nRainie Xie\n\n\nMay 29, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nA Replication of Karlan and List (2007)\n\n\n\n\n\n\nRainie Xie\n\n\nMay 29, 2024\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "homeworks/hw1/hw1_questions.html",
    "href": "homeworks/hw1/hw1_questions.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nUsing direct mail solicitations to over 50,000 prior donors of a non-profit organization, the experiment tests how different matching grant offers affect the likelihood and amount of donations. The study finds that announcing a match offer significantly increases both the revenue per solicitation and the likelihood of receiving donations, but higher matching ratios ($2:$1, $3:$1) do not significantly boost donations compared to a $1:$1 ratio. The study also tested on heterogeneous treatment effects to observe the differences in political environments across different solicitees.\n\n\n\nParticipants: 50,083 prior donors to a liberal nonprofit organization.\n\nMethodology: Donors were randomly assigned to either a control group or one of several matching grant conditions, where their donations would be matched at different ratios. The control group received a standard donation request, while treatment groups received requests indicating that their donations would be matched by a leadership donor.\n\nVariables Tested:\n\nMatching ratios: $1:$1, $2:$1, and $3:$1.\n\nMaximum matching amounts: $25,000; $50,000; $100,000; unstated.\n\nSuggested donation amounts: based on the donor’s highest previous contribution, increased by 25% and 50%.\n\n\nOutcome Measures: Donation frequency (response rate) and amount donated (revenue per solicitation).\n\nImpact of Matching on Donations: Announcing a match increased donations by 19% and likelihood of donating by 22%.\n\nThis project seeks to replicate their results."
  },
  {
    "objectID": "homeworks/hw1/hw1_questions.html#introduction",
    "href": "homeworks/hw1/hw1_questions.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nUsing direct mail solicitations to over 50,000 prior donors of a non-profit organization, the experiment tests how different matching grant offers affect the likelihood and amount of donations. The study finds that announcing a match offer significantly increases both the revenue per solicitation and the likelihood of receiving donations, but higher matching ratios ($2:$1, $3:$1) do not significantly boost donations compared to a $1:$1 ratio. The study also tested on heterogeneous treatment effects to observe the differences in political environments across different solicitees.\n\n\n\nParticipants: 50,083 prior donors to a liberal nonprofit organization.\n\nMethodology: Donors were randomly assigned to either a control group or one of several matching grant conditions, where their donations would be matched at different ratios. The control group received a standard donation request, while treatment groups received requests indicating that their donations would be matched by a leadership donor.\n\nVariables Tested:\n\nMatching ratios: $1:$1, $2:$1, and $3:$1.\n\nMaximum matching amounts: $25,000; $50,000; $100,000; unstated.\n\nSuggested donation amounts: based on the donor’s highest previous contribution, increased by 25% and 50%.\n\n\nOutcome Measures: Donation frequency (response rate) and amount donated (revenue per solicitation).\n\nImpact of Matching on Donations: Announcing a match increased donations by 19% and likelihood of donating by 22%.\n\nThis project seeks to replicate their results."
  },
  {
    "objectID": "homeworks/hw1/hw1_questions.html#data",
    "href": "homeworks/hw1/hw1_questions.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nDescription\n\nimport pandas as pd \n\n# Load data \ndata = pd.read_stata('karlan_list_2007.dta')\n\ndata.describe(include='all')\n\n\n\n\n\n\n\n\n\ntreatment\ncontrol\nratio\nratio2\nratio3\nsize\nsize25\nsize50\nsize100\nsizeno\n...\nredcty\nbluecty\npwhite\npblack\npage18_39\nave_hh_sz\nmedian_hhincome\npowner\npsch_atlstba\npop_propurban\n\n\n\n\ncount\n50083.000000\n50083.000000\n50083\n50083.000000\n50083.000000\n50083\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n...\n49978.000000\n49978.000000\n48217.000000\n48047.000000\n48217.000000\n48221.000000\n48209.000000\n48214.000000\n48215.000000\n48217.000000\n\n\nunique\nNaN\nNaN\n4\nNaN\nNaN\n5\nNaN\nNaN\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\ntop\nNaN\nNaN\nControl\nNaN\nNaN\nControl\nNaN\nNaN\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\nfreq\nNaN\nNaN\n16687\nNaN\nNaN\n16687\nNaN\nNaN\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\nmean\n0.666813\n0.333187\nNaN\n0.222311\n0.222211\nNaN\n0.166723\n0.166623\n0.166723\n0.166743\n...\n0.510245\n0.488715\n0.819599\n0.086710\n0.321694\n2.429012\n54815.700533\n0.669418\n0.391661\n0.871968\n\n\nstd\n0.471357\n0.471357\nNaN\n0.415803\n0.415736\nNaN\n0.372732\n0.372643\n0.372732\n0.372750\n...\n0.499900\n0.499878\n0.168560\n0.135868\n0.103039\n0.378105\n22027.316665\n0.193405\n0.186599\n0.258633\n\n\nmin\n0.000000\n0.000000\nNaN\n0.000000\n0.000000\nNaN\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.000000\n0.000000\n0.009418\n0.000000\n0.000000\n0.000000\n5000.000000\n0.000000\n0.000000\n0.000000\n\n\n25%\n0.000000\n0.000000\nNaN\n0.000000\n0.000000\nNaN\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.000000\n0.000000\n0.755845\n0.014729\n0.258311\n2.210000\n39181.000000\n0.560222\n0.235647\n0.884929\n\n\n50%\n1.000000\n0.000000\nNaN\n0.000000\n0.000000\nNaN\n0.000000\n0.000000\n0.000000\n0.000000\n...\n1.000000\n0.000000\n0.872797\n0.036554\n0.305534\n2.440000\n50673.000000\n0.712296\n0.373744\n1.000000\n\n\n75%\n1.000000\n1.000000\nNaN\n0.000000\n0.000000\nNaN\n0.000000\n0.000000\n0.000000\n0.000000\n...\n1.000000\n1.000000\n0.938827\n0.090882\n0.369132\n2.660000\n66005.000000\n0.816798\n0.530036\n1.000000\n\n\nmax\n1.000000\n1.000000\nNaN\n1.000000\n1.000000\nNaN\n1.000000\n1.000000\n1.000000\n1.000000\n...\n1.000000\n1.000000\n1.000000\n0.989622\n0.997544\n5.270000\n200001.000000\n1.000000\n1.000000\n1.000000\n\n\n\n\n11 rows × 51 columns\n\n\n\n\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\nThe dataset consists of 50,083 observations and multiple columns that correspond to different variables within the study. The treatment group consists of 33,396 observations, and the control group consists of 16,687 observations. Note that the description includes both numerical and categorical data, with some summary statistics such as count, unique, top (most common value), and frequency for categorical data, and count, mean, etc., for numerical data.\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\n\nfrom scipy import stats\nimport statsmodels.api as sm \n\n# First, we'll perform a t-test for the 'mrm2' variable\n# 'mrm2' stands for the number of months since last donation\n\ntreatment_group = data[data['treatment'] == 1]['mrm2'].dropna()\ncontrol_group = data[data['treatment'] == 0]['mrm2'].dropna()\n\n# Perform the t-test\nt_test_result = stats.ttest_ind(treatment_group, control_group, equal_var=False)\n\n# Then, run a linear regression for the 'mrm2' variable \nX = sm.add_constant(data['treatment'])\ny = data['mrm2'] \n\n# Perform the linear regression\nmodel = sm.OLS(y, X, missing='drop').fit()\n\n# Print the results \nprint(t_test_result)\nprint(model.summary()) \n\nTtestResult(statistic=0.11953155228177251, pvalue=0.9048549631450832, df=33394.47581389535)\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   mrm2   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                 -0.000\nMethod:                 Least Squares   F-statistic:                   0.01428\nDate:                Fri, 03 May 2024   Prob (F-statistic):              0.905\nTime:                        15:55:08   Log-Likelihood:            -1.9585e+05\nNo. Observations:               50082   AIC:                         3.917e+05\nDf Residuals:                   50080   BIC:                         3.917e+05\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst         12.9981      0.094    138.979      0.000      12.815      13.181\ntreatment      0.0137      0.115      0.119      0.905      -0.211       0.238\n==============================================================================\nOmnibus:                     8031.352   Durbin-Watson:                   2.004\nProb(Omnibus):                  0.000   Jarque-Bera (JB):            12471.135\nSkew:                           1.163   Prob(JB):                         0.00\nKurtosis:                       3.751   Cond. No.                         3.23\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\nResult forboth the t-test and the linear regression for the variable ‘mrm2’ (months since last donation) are consistent:\n\nT-test: The t-statistic is approximately 0.119, with a p-value of about 0.905. This indicates that there is no statistically significant difference in the mean number of months since last donation between the treatment and control groups at the 95% confidence level.\n\nLinear Regression: The regression coefficient for the ‘treatment’ variable is approximately 0.0137 with a standard error of about 0.115. The p-value for this coefficient is about 0.905, which also indicates that there is no statistically significant difference between the treatment and control groups.\n\n\n\n\n\n\n\nMore Tests for the Randomization Mechanism\n\n\n\n\n\n\n# Let's conduct similar balance tests for other variables. \n\n# Perform a t-test for the 'female' variable\ntreatment_group_female = data[data['treatment'] == 1]['female'].dropna()\ncontrol_group_female = data[data['treatment'] == 0]['female'].dropna()\n\n# Perform the t-test\nt_test_result_female = stats.ttest_ind(treatment_group_female, control_group_female)\n\n# Linear regression for 'female' on 'treatment'\nX_female = sm.add_constant(data['treatment'])\ny_female = data['female'] \n\n# Perform the linear regression\nmodel_female = sm.OLS(y_female, X_female, missing='drop').fit()\n\n# Print the results \nprint(t_test_result_female)\nprint(model_female.summary()) \n\n# Perform a t-test for Highest previous contribution the 'hpa' variable\ntreatment_group_hpa = data[data['treatment'] == 1]['hpa'].dropna()\ncontrol_group_hpa = data[data['treatment'] == 0]['hpa'].dropna()\n\n# Perform the t-test\nt_test_result_hpa = stats.ttest_ind(treatment_group_hpa, control_group_hpa)\n\n# Linear regression for 'female' on 'treatment'\nX_hpa = sm.add_constant(data['treatment'])\ny_hpa = data['hpa'] \n\n# Perform the linear regression\nmodel_hpa = sm.OLS(y_hpa, X_hpa, missing='drop').fit()\n\n# Print the results \nprint(t_test_result_hpa)\nprint(model_hpa.summary()) \n\nTtestResult(statistic=-1.7583691871450704, pvalue=0.07869095826986475, df=48970.0)\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                 female   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                  0.000\nMethod:                 Least Squares   F-statistic:                     3.092\nDate:                Fri, 03 May 2024   Prob (F-statistic):             0.0787\nTime:                        15:55:08   Log-Likelihood:                -30148.\nNo. Observations:               48972   AIC:                         6.030e+04\nDf Residuals:                   48970   BIC:                         6.032e+04\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst          0.2827      0.004     80.688      0.000       0.276       0.290\ntreatment     -0.0075      0.004     -1.758      0.079      -0.016       0.001\n==============================================================================\nOmnibus:                    17873.494   Durbin-Watson:                   2.004\nProb(Omnibus):                  0.000   Jarque-Bera (JB):            10142.985\nSkew:                           0.993   Prob(JB):                         0.00\nKurtosis:                       1.986   Cond. No.                         3.22\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\nTtestResult(statistic=0.944145044786662, pvalue=0.34510008823759086, df=50081.0)\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                    hpa   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                 -0.000\nMethod:                 Least Squares   F-statistic:                    0.8924\nDate:                Fri, 03 May 2024   Prob (F-statistic):              0.345\nTime:                        15:55:08   Log-Likelihood:            -2.8468e+05\nNo. Observations:               50083   AIC:                         5.694e+05\nDf Residuals:                   50081   BIC:                         5.694e+05\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst         58.9602      0.551    107.005      0.000      57.880      60.040\ntreatment      0.6371      0.675      0.944      0.345      -0.685       1.960\n==============================================================================\nOmnibus:                    66199.149   Durbin-Watson:                   2.003\nProb(Omnibus):                  0.000   Jarque-Bera (JB):         14448195.271\nSkew:                           7.552   Prob(JB):                         0.00\nKurtosis:                      84.826   Cond. No.                         3.23\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\n\n\n\nThe results for both the t-test and the linear regression for the variables ‘female’ and ‘hpa’ are consistent similar to the ‘mrm2’, indicating that the treatment and control groups are not significantly different at the 95% confidence level. Based on these 3 tests, it supports the notion that the treatment and control groups are balanced with respect to the randomization mechanism. Refer to the Table 1 on the paper, the treatment and control groups are quite similar in mean and standar deviation across all the variables listed, suggesting good balance."
  },
  {
    "objectID": "homeworks/hw1/hw1_questions.html#experimental-results",
    "href": "homeworks/hw1/hw1_questions.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\n\nBarplot with proportion of people who donated.\n\nimport matplotlib.pyplot as plt\n\n# Calculate the proportion of people who donated in both treatment and control groups\nprop_donated_treatment = data[data['treatment'] == 1]['gave'].mean()\nprop_donated_control = data[data['treatment'] == 0]['gave'].mean()\n\n# Data to plot\nproportions = [prop_donated_treatment, prop_donated_control]\nbar_labels = ['Treatment', 'Control']\n\n# Create the barplot\nplt.figure(figsize=(10, 6))\nplt.bar(bar_labels, proportions, color=['blue', 'orange'])\n\n# Title and labels\nplt.title('Proportion of People Who Donated by Group')\nplt.ylabel('Proportion of People')\nplt.xlabel('Group')\n\n# Show the plot\nplt.show()\n\n\n\n\n\n\n\n\nNote: Results from this barplot are consistent with the results in Table 2a Panel A.\n\n\n\nT-test & Linear Regression on Charitable Contribution\n\n# T-test for 'gave' variable\ntreatment_gave = data[data['treatment'] == 1]['gave'].dropna()\ncontrol_gave = data[data['treatment'] == 0]['gave'].dropna()\nt_test_result_gave = stats.ttest_ind(treatment_gave, control_gave)\n\n# Bivariate linear regression: regressing 'gave' on 'treatment'\nX_donation = sm.add_constant(data['treatment'])\ny_donation = data['gave']\n\n# Regression model\ndonation_model = sm.OLS(y_donation, X_donation, missing='drop').fit()\n\n# Print results \nprint(t_test_result_gave) \nprint(donation_model.summary())\n\nTtestResult(statistic=3.101361000543946, pvalue=0.0019274025949016986, df=50081.0)\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   gave   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                  0.000\nMethod:                 Least Squares   F-statistic:                     9.618\nDate:                Fri, 03 May 2024   Prob (F-statistic):            0.00193\nTime:                        15:55:08   Log-Likelihood:                 26630.\nNo. Observations:               50083   AIC:                        -5.326e+04\nDf Residuals:                   50081   BIC:                        -5.324e+04\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst          0.0179      0.001     16.225      0.000       0.016       0.020\ntreatment      0.0042      0.001      3.101      0.002       0.002       0.007\n==============================================================================\nOmnibus:                    59814.280   Durbin-Watson:                   2.005\nProb(Omnibus):                  0.000   Jarque-Bera (JB):          4317152.727\nSkew:                           6.740   Prob(JB):                         0.00\nKurtosis:                      46.440   Cond. No.                         3.23\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\nResults:\n1. T-test Results: The t-statistic is 3.101 with a p-value of approximately 0.0019. Since the p-value is less than 0.05, this suggests that there is a statistically significant difference in the likelihood of making a donation between the treatment and control groups. This means that those in the treatment group (who received the matched donations letter) were significantly more likely to donate than those in the control group (who received a standard donation request).\n2. Linear Regression Results: The regression coefficient for the treatment variable is 0.0042 with a standard error of 0.001. The t-statistic for the treatment variable is also 3.101, which corresponds with the t-test result, and the p-value is 0.002, confirming the finding from the t-test. This indicates a statistically significant effect of the treatment on the likelihood of giving a donation. Since the dependent variable gave is binary, this coefficient can be interpreted as the difference in the probability of giving between the treatment and control groups.\nThe consistency between the t-test and regression analysis reinforces the validity of the findings. The practical interpretation is that being in the treatment group (i.e., receiving a matched donation solicitation) is associated with a higher likelihood of donating compared to being in the control group. This provides evidence that the match donation strategy employed is effective in increasing the rate of charitable contributions.\nThese results tell us about human behavior regarding incentives and charitable giving. Specifically, they suggest that potential donors are more likely to contribute when they feel their donation has a larger impact, which is implied by the matching of their donations.\n\n\nProbit Model on Charitable Contribution\n\nfrom statsmodels.discrete.discrete_model import Probit\n\n# Preparing the data for the Probit model\nX_probit = sm.add_constant(data['treatment'])\ny_probit = data['gave']\n\n# Fit the Probit model\nprobit_model = Probit(y_probit, X_probit).fit()\n\n# Display the summary of the model\nprint(probit_model.summary())\n\nOptimization terminated successfully.\n         Current function value: 0.100443\n         Iterations 7\n                          Probit Regression Results                           \n==============================================================================\nDep. Variable:                   gave   No. Observations:                50083\nModel:                         Probit   Df Residuals:                    50081\nMethod:                           MLE   Df Model:                            1\nDate:                Fri, 03 May 2024   Pseudo R-squ.:               0.0009783\nTime:                        15:55:09   Log-Likelihood:                -5030.5\nconverged:                       True   LL-Null:                       -5035.4\nCovariance Type:            nonrobust   LLR p-value:                  0.001696\n==============================================================================\n                 coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst         -2.1001      0.023    -90.073      0.000      -2.146      -2.054\ntreatment      0.0868      0.028      3.113      0.002       0.032       0.141\n==============================================================================\n\n\nThe coefficient for the treatment variable is 0.0868, with a standard error of 0.028. The z-statistic for the treatment effect is 3.113, with a corresponding p-value of 0.002. These results indicate that the effect of treatment on the probability of making a donation is positive and statistically significant at the 1% level (since the p-value is below 0.01). This means that being in the treatment group makes a statistically significant increase in the likelihood of donating compared to the control group, holding other factors constant.\nIn the context of the experiment, this finding tells us that the treatment (which likely involves receiving a matched donation offer) is effective in increasing the propensity to give among the recipients of the fundraising letters.\nHowever, the coefficient is different from the one reported in Table 3, while the result from previous OLS regression matched with Table 3. Need further analysis.\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate. :::: {.callout-note collapse=“true”} ### T-tests between different match ratios\n\n# Subset the data based on match ratio\ndata_1to1 = data[data['ratio'] == 1]['gave']\ndata_2to1 = data[data['ratio2'] == 1]['gave']\ndata_3to1 = data[data['ratio3'] == 1]['gave']\n\n# Perform t-tests between the different match ratios\nttest_results_1to1_vs_2to1 = stats.ttest_ind(data_1to1.dropna(), data_2to1.dropna())\nttest_results_1to1_vs_3to1 = stats.ttest_ind(data_1to1.dropna(), data_3to1.dropna())\nttest_results_2to1_vs_3to1 = stats.ttest_ind(data_2to1.dropna(), data_3to1.dropna())\n\n# Print results\nprint(\"1:1 vs 2:1 Match Ratio:\", ttest_results_1to1_vs_2to1)\nprint(\"1:1 vs 3:1 Match Ratio:\", ttest_results_1to1_vs_3to1)\nprint(\"2:1 vs 3:1 Match Ratio:\", ttest_results_2to1_vs_3to1)\n\n1:1 vs 2:1 Match Ratio: TtestResult(statistic=-0.96504713432247, pvalue=0.33453168549723933, df=22265.0)\n1:1 vs 3:1 Match Ratio: TtestResult(statistic=-1.0150255853798622, pvalue=0.31010466370866724, df=22260.0)\n2:1 vs 3:1 Match Ratio: TtestResult(statistic=-0.05011583793874515, pvalue=0.9600305283739325, df=22261.0)\n\n\n::::\nThese results with high p-values indicate that the match ratios are not significantly different from each other, statistically the size of the match ratio did not significantly affeect whether people donate or not. This finding would support the authors’ suggestion that increasing the match ratio from 1:1 to 2:1 or 3:1 does not seem to increase the likelihood of someone donating.\n\n\n\n\n\n\nRegression on different match ratios\n\n\n\n\n\n\n# Create the variable 'ratio1' \ndata['ratio1'] = (data['ratio'] == 1).astype(int)\n\n# Create the regression model\nX = sm.add_constant(data[['ratio1', 'ratio2', 'ratio3']])\ny = data['gave']\n# Fit the regression model\nregression_model_ratio = sm.OLS(y, X, missing='drop').fit()\n\n# Output the summary of the model\nprint(regression_model_ratio.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   gave   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                  0.000\nMethod:                 Least Squares   F-statistic:                     3.665\nDate:                Fri, 03 May 2024   Prob (F-statistic):             0.0118\nTime:                        15:55:09   Log-Likelihood:                 26630.\nNo. Observations:               50083   AIC:                        -5.325e+04\nDf Residuals:                   50079   BIC:                        -5.322e+04\nDf Model:                           3                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst          0.0179      0.001     16.225      0.000       0.016       0.020\nratio1         0.0029      0.002      1.661      0.097      -0.001       0.006\nratio2         0.0048      0.002      2.744      0.006       0.001       0.008\nratio3         0.0049      0.002      2.802      0.005       0.001       0.008\n==============================================================================\nOmnibus:                    59812.754   Durbin-Watson:                   2.005\nProb(Omnibus):                  0.000   Jarque-Bera (JB):          4316693.217\nSkew:                           6.740   Prob(JB):                         0.00\nKurtosis:                      46.438   Cond. No.                         4.26\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\n\n\n\nBased on the regression output:\n‘ratio1’: The coefficient for the 1:1 match ratio is 0.0029 with a p-value of 0.097. This suggests that the effect of the 1:1 match ratio on the likelihood of donating is not statistically significant at the 0.05 level. The coefficient indicates a small increase in the probability of giving compared to the baseline category, but this result is not statistically robust. ‘ratio2’: The coefficient for ratio2 (0.0048) is statistically significant (p &lt; 0.05), which indicates that there is a significant difference in the likelihood of donating between the 2:1 match and the baseline, with a 0.48 percentage point increase. ‘ratio3’: The coefficient for ratio3 (0.0049) is also statistically significant (p &lt; 0.05), suggesting a 0.49 percentage point increase in the likelihood of donating for the 3:1 match.\n\n\n\n\n\n\nResponse Rate Difference\n\n\n\n\n\n\n# Calculating response rates directly from the data\nmean_response_1to1 = data[data['ratio1'] == 1]['gave'].mean()\nmean_response_2to1 = data[data['ratio2'] == 1]['gave'].mean()\nmean_response_3to1 = data[data['ratio3'] == 1]['gave'].mean()\n\n# Calculating the differences in response rates\ndiff_response_1to1_vs_2to1 = mean_response_2to1 - mean_response_1to1\ndiff_response_2to1_vs_3to1 = mean_response_3to1 - mean_response_2to1\n\n# Now calculate the differences using the regression coefficients\ncoef_1to1 = regression_model_ratio.params['ratio1']\ncoef_2to1 = regression_model_ratio.params['ratio2']\ncoef_3to1 = regression_model_ratio.params['ratio3']\n\ndiff_coef_1to1_vs_2to1 = coef_2to1 - coef_1to1\ndiff_coef_2to1_vs_3to1 = coef_3to1 - coef_2to1\n\nprint(\"Directly from data:\")\nprint(\"1:1 vs 2:1 Match Ratio Response Rate Difference:\", diff_response_1to1_vs_2to1)\nprint(\"2:1 vs 3:1 Match Ratio Response Rate Difference:\", diff_response_2to1_vs_3to1)\n\nprint(\"\\nFrom regression coefficients:\")\nprint(\"1:1 vs 2:1 Match Ratio Coefficient Difference:\", diff_coef_1to1_vs_2to1)\nprint(\"2:1 vs 3:1 Match Ratio Coefficient Difference:\", diff_coef_2to1_vs_3to1)\n\nDirectly from data:\n1:1 vs 2:1 Match Ratio Response Rate Difference: 0.0018842510217149944\n2:1 vs 3:1 Match Ratio Response Rate Difference: 0.00010002398025293902\n\nFrom regression coefficients:\n1:1 vs 2:1 Match Ratio Coefficient Difference: 0.0018842510217131837\n2:1 vs 3:1 Match Ratio Coefficient Difference: 0.00010002398025347158\n\n\n\n\n\nBased on the results provided, both the direct data calculation and the regression coefficients yield very similar findings:\n\nThe difference in response rate between the 1:1 and 2:1 match ratios is approximately 0.1884 percentage points.\n\nThe difference in response rate between the 2:1 and 3:1 match ratios is approximately 0.0100 percentage points.\nThese differences are quite small, indicating that while there is a slight increase in the likelihood of donating when moving from a 1:1 to a 2:1 match ratio, the further increase from a 2:1 to a 3:1 match ratio is even smaller and practically negligible.\n\nConclusions regarding the effectiveness of different sizes of matched donations:\n1:1 vs 2:1 Match Ratio: There is a small but potentially meaningful increase in donation likelihood when the match ratio is increased from 1:1 to 2:1. This suggests that donors may be somewhat responsive to a more generous match offer, though the effect is not large.\n2:1 vs 3:1 Match Ratio: The extremely small increase when moving from a 2:1 to a 3:1 match ratio suggests that there is very little to gain in donation likelihood by offering a more generous match beyond 2:1. This increment is so small that it is likely to be of limited practical significance.\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\n\nT-test on Donation Amount\n\n# Separate the donation amounts by treatment status\ntreatment_amounts = data[data['treatment'] == 1]['amount']\ncontrol_amounts = data[data['treatment'] == 0]['amount']\n\n# Perform the t-test\nt_test_results = stats.ttest_ind(treatment_amounts.dropna(), control_amounts.dropna())\n\n# Print the t-test results\nprint(t_test_results)\n\nTtestResult(statistic=1.8605020225753781, pvalue=0.06282038947470683, df=50081.0)\n\n\nSince the p-value is greater than 0.05, there is not enough evidence to reject the null hypothesis that there is no difference in the average donation amount between the treatment and control groups.\nEffect Size: The positive t-statistic indicates that the treatment group’s mean donation amount is higher than that of the control group, but since the p-value is not below 0.05, this difference is not statistically significant.\nIt’s important to consider the practical significance. Given the p-value is relatively close to 0.05, it may also be worthwhile to look at other factors or conduct further research.\n\n\nRegression on Donation Amount with people who donated\n\n# Filter the dataset for only those individuals who made a donation\ndonor_data = data[data['gave'] == 1]\n\nX = sm.add_constant(donor_data['treatment'])\n\ny = donor_data['amount']\n\n# Fit the regression model for this subset of donors\nregression_model_donor = sm.OLS(y, X, missing='drop').fit()\n\n# Output the summary of the model\nprint(regression_model_donor.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                 amount   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                 -0.001\nMethod:                 Least Squares   F-statistic:                    0.3374\nDate:                Fri, 03 May 2024   Prob (F-statistic):              0.561\nTime:                        15:55:09   Log-Likelihood:                -5326.8\nNo. Observations:                1034   AIC:                         1.066e+04\nDf Residuals:                    1032   BIC:                         1.067e+04\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst         45.5403      2.423     18.792      0.000      40.785      50.296\ntreatment     -1.6684      2.872     -0.581      0.561      -7.305       3.968\n==============================================================================\nOmnibus:                      587.258   Durbin-Watson:                   2.031\nProb(Omnibus):                  0.000   Jarque-Bera (JB):             5623.279\nSkew:                           2.464   Prob(JB):                         0.00\nKurtosis:                      13.307   Cond. No.                         3.49\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\nThe treatment coefficient is -1.6684 with a p-value of 0.561, which is not statistically significant at the conventional 0.05 level. This indicates that the treatment does not have a statistically significant impact on the donation amount for those who chose to donate.\nThe lack of significance of the treatment coefficient suggests that there is no strong evidence that the treatment (such as being offered a matched donation) significantly influences the amount donated by those who decided to donate. Even though the treatment was randomly assigned, the lack of statistical significance in this context means we cannot conclusively say that there is a causal effect of the treatment on the amount donated. From this analysis, we learn that while the treatment might influence the decision to donate in the first place, among those who do decide to donate, the treatment doesn’t significantly affect the amount they choose to donate. This could indicate that other factors may play a more crucial role in determining the size of the donation once the decision to donate has been made.\n\n\n\n\n\n\nHistogram of Donation Amount for those who donated\n\n\n\n\n\n\n# Separate the donation amounts by treatment status\ntreatment_donations = donor_data[donor_data['treatment'] == 1]['amount']\ncontrol_donations = donor_data[donor_data['treatment'] == 0]['amount']\n\n# Calculate the sample averages\navg_treatment_donations = treatment_donations.mean()\navg_control_donations = control_donations.mean()\n\n# Create histogram for the treatment group\nplt.figure(figsize=(14, 7))\n\n# Treatment group plot\nplt.subplot(1, 2, 1)\nplt.hist(treatment_donations, bins=30, color='blue', alpha=0.7)\nplt.axvline(avg_treatment_donations, color='red', linestyle='dashed', linewidth=2)\nplt.title('Treatment Group Donations')\nplt.xlabel('Donation Amount')\nplt.ylabel('Frequency')\nplt.annotate('Average: ${:.2f}'.format(avg_treatment_donations), \n             xy=(avg_treatment_donations, 5), \n             xytext=(avg_treatment_donations, 10),\n             arrowprops=dict(facecolor='red', shrink=0.05))\n\n# Control group plot\nplt.subplot(1, 2, 2)\nplt.hist(control_donations, bins=30, color='green', alpha=0.7)\nplt.axvline(avg_control_donations, color='red', linestyle='dashed', linewidth=2)\nplt.title('Control Group Donations')\nplt.xlabel('Donation Amount')\nplt.ylabel('Frequency')\nplt.annotate('Average: ${:.2f}'.format(avg_control_donations), \n             xy=(avg_control_donations, 5), \n             xytext=(avg_control_donations, 10),\n             arrowprops=dict(facecolor='red', shrink=0.05))\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "homeworks/hw1/hw1_questions.html#simulation-experiment",
    "href": "homeworks/hw1/hw1_questions.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\n\nimport numpy as np \n# Parameters for the simulation\ntrue_p_control = 0.018  # The true probability for the control group\ntrue_p_treatment = 0.022  # The true probability for the treatment group\nn_simulations = 10000\n\n# Simulate 100,000 draws from the control distribution \ncontrol_draws = np.random.binomial(1, true_p_control, 100000)\n\n# Simulate 10,000 draws from the treatment distribution \ntreatment_draws = np.random.binomial(1, true_p_treatment, 10000)\n\n# Calculate the cumulative average of donations for control and treatment\ncumulative_avg_control = np.cumsum(control_draws) / np.arange(1, 100001)\ncumulative_avg_treatment = np.cumsum(treatment_draws) / np.arange(1, 10001)\n\n# Calculate a vector of 10,000 differences between treatment and control cumulative averages\n# Since the control has more observations, slice it to match the treatment's size\ndifferences = cumulative_avg_treatment - cumulative_avg_control[:10000]\n\n# Plot the cumulative average of the vector of differences\nplt.figure(figsize=(14, 7))\nplt.plot(differences, label='Cumulative Average of Differences')\nplt.hlines(true_p_treatment - true_p_control, xmin=0, xmax=n_simulations, color='red', linestyles='dashed', label='True Difference')\nplt.legend()\nplt.title('Cumulative Average of Differences Between Treatment and Control')\nplt.xlabel('Number of Simulations')\nplt.ylabel('Cumulative Average of Donation Probability Difference')\nplt.ylim(-0.1, 0.01)\nplt.show()\n\n\n\n\n\n\n\n\nThe blue line represents the cumulative average of the differences between the treatment and control groups across the simulations.\nThe dashed red line represents the true difference in probabilities between the treatment and control groups, which is 0.004 (from p=0.022 for treatment minus p=0.018 for control).\nAfter initial volatility due to the small sample size, the blue line starts to stabilize and converge toward the dashed red line, which is the expected behavior according to the Law of Large Numbers. As the number of simulations increases, the cumulative average difference becomes less variable and fluctuates around the true difference of 0.004. The simulation confirms the Law of Large Numbers, as the cumulative average difference approaches the true difference with a large enough number of simulations. This demonstrates that with a sufficiently large sample size, the sample mean will provide a good estimate of the population mean.\n\n\nCentral Limit Theorem\n\n# Parameters for the simulation\nn_draws_list = [50, 200, 500, 1000]\nn_replications = 1000\navg_diffs = {}\n\n# Function to perform simulation for different sample sizes\ndef simulate_diffs(n, replications, p_control, p_treatment):\n    diffs = []\n    for _ in range(replications):\n        control_sample = np.random.binomial(1, p_control, n)\n        treatment_sample = np.random.binomial(1, p_treatment, n)\n        diffs.append(treatment_sample.mean() - control_sample.mean())\n    return diffs\n\n# Run simulations for each sample size\nfor n_draws in n_draws_list:\n    avg_diffs[n_draws] = simulate_diffs(n_draws, n_replications, true_p_control, true_p_treatment)\n\n# Create histograms\nplt.figure(figsize=(16, 8))\nfor i, n_draws in enumerate(n_draws_list, 1):\n    plt.subplot(2, 2, i)\n    plt.hist(avg_diffs[n_draws], bins=30, color='skyblue', edgecolor='black')\n    plt.axvline(x=0, color='red', linestyle='dashed', linewidth=2)\n    plt.title(f'Histogram of 1000 Sample Averages at N={n_draws}')\n    plt.xlabel('Average Difference')\n    plt.ylabel('Frequency')\n    plt.axvline(true_p_treatment - true_p_control, color='green', linestyle='dashed', linewidth=2, label='True Difference')\n\nplt.show()\n\n\n\n\n\n\n\n\nEach histogram represents the distribution of 1000 sample averages, calculated by taking 50, 200, 500, and 1000 draws from both the control and treatment distributions and finding the average difference between those draws. The vertical dashed red line indicates zero difference, while the vertical dashed green line indicates the true difference in the population.\n\nHistogram at N=50: This histogram shows a wide spread of the sample averages, with a considerable variance around zero. The true difference seems to be in the middle of the distribution, suggesting that when you take small sample sizes, the sample mean can vary significantly.\n\nHistogram at N=200: As the sample size increases to 200, the histogram starts to take on a more bell-shaped curve, indicating the beginning of normal distribution in accordance with the Central Limit Theorem. Zero is still around the center of the distribution, and the variance is decreasing.\n\nHistogram at N=500: With a sample size of 500, the distribution of the sample averages becomes tighter and more symmetric around the true difference, showing less uncertainty and further confirmation of the Central Limit Theorem.\n\nHistogram at N=1000: At this sample size, the histogram clearly shows a normal distribution around the true difference, and zero is not in the tail of the distribution. The average differences are centering more closely around the true difference."
  },
  {
    "objectID": "homeworks/hw1/hw1_questions.html#results",
    "href": "homeworks/hw1/hw1_questions.html#results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Results:",
    "text": "Results:\ntodo: run a probit regression where the outcome variable is whether any charitable donation was made and the explanatory variable is assignment to treatment or control. Confirm that your results replicate Table 3 column 1 in the paper.\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\ntodo: Use a series of t-tests to test whether the size of the match ratio has an effect on whether people donate or not. For example, does the 2:1 match rate lead increase the likelihood that someone donates as compared to the 1:1 match rate? Do your results support the “figures suggest” comment the authors make on page 8?\ntodo: Assess the same issue using a regression. Specifically, create the variable ratio1 then regress gave on ratio1, ratio2, and ratio3 (or alternatively, regress gave on the categorical variable ratio). Interpret the coefficients and their statistical precision.\ntodo: Calculate the response rate difference between the 1:1 and 2:1 match ratios and the 2:1 and 3:1 ratios. Do this directly from the data, and do it by computing the differences in the fitted coefficients of the previous regression. what do you conclude regarding the effectiveness of different sizes of matched donations?\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\ntodo: Calculate a t-test or run a bivariate linear regression of the donation amount on the treatment status. What do we learn from doing this analysis?\ntodo: now limit the data to just people who made a donation and repeat the previous analysis. This regression allows you to analyze how much respondents donate conditional on donating some positive amount. Interpret the regression coefficients – what did we learn? Does the treatment coefficient have a causal interpretation?\ntodo: Make two plot: one for the treatment group and one for the control. Each plot should be a histogram of the donation amounts only among people who donated. Add a red vertical bar or some other annotation to indicate the sample average for each plot."
  },
  {
    "objectID": "homeworks/hw2/hw2_questions.html",
    "href": "homeworks/hw2/hw2_questions.html",
    "title": "Poisson Regression Examples",
    "section": "",
    "text": "Blueprinty is a small firm that makes software for developing blueprints specifically for submitting patent applications to the US patent office. Their marketing team would like to make the claim that patent applicants using Blueprinty’s software are more successful in getting their patent applications approved. Ideal data to study such an effect might include the success rate of patent applications before using Blueprinty’s software and after using it. unfortunately, such data is not available.\nHowever, Blueprinty has collected data on 1,500 mature (non-startup) engineering firms. The data include each firm’s number of patents awarded over the last 5 years, regional location, age since incorporation, and whether or not the firm uses Blueprinty’s software. The marketing team would like to use this data to make the claim that firms using Blueprinty’s software are more successful in getting their patent applications approved.\n\n\n\n\nimport pandas as pd \n# Load dataset \nblueprinty = pd.read_csv(\"./blueprinty.csv\")\n\n# Summarize data\nblueprinty.describe() \n\n\n\n\n\n\n\n\n\nUnnamed: 0\npatents\nage\niscustomer\n\n\n\n\ncount\n1500.000000\n1500.000000\n1500.000000\n1500.000000\n\n\nmean\n750.500000\n3.684667\n26.357667\n0.131333\n\n\nstd\n433.157015\n2.352500\n7.242528\n0.337877\n\n\nmin\n1.000000\n0.000000\n9.000000\n0.000000\n\n\n25%\n375.750000\n2.000000\n21.000000\n0.000000\n\n\n50%\n750.500000\n3.000000\n26.000000\n0.000000\n\n\n75%\n1125.250000\n5.000000\n31.625000\n0.000000\n\n\nmax\n1500.000000\n16.000000\n49.000000\n1.000000\n\n\n\n\n\n\n\n\n\n\nWe’ll visualize the distributions and calculate the mean number of patents by customer status.\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Calculate the mean number of patents for customers and non-customers\nmean_patents_customers = blueprinty[blueprinty['iscustomer'] == 1]['patents'].mean()\nmean_patents_non_customers = blueprinty[blueprinty['iscustomer'] == 0]['patents'].mean()\n\nprint(f\"Mean number of patents for customers: {mean_patents_customers}\")\nprint(f\"Mean number of patents for non-customers: {mean_patents_non_customers}\")\n\n# Plot histograms\nplt.figure(figsize=(12, 6))\nsns.histplot(blueprinty[blueprinty['iscustomer'] == 1]['patents'], color='blue', label='Customers', kde=False)\nsns.histplot(blueprinty[blueprinty['iscustomer'] == 0]['patents'], color='red', label='Non-Customers', kde=False)\nplt.title('Distribution of Number of Patents Awarded by Customer Status')\nplt.xlabel('Number of Patents Awarded')\nplt.ylabel('Frequency')\nplt.legend()\nplt.show()\n\nMean number of patents for customers: 4.091370558375634\nMean number of patents for non-customers: 3.6231772831926325\n\n\n\n\n\n\n\n\n\nMeans: The mean number of patents for customers is approximately 4.09, which is higher than the mean for non-customers at about 3.62. This suggests that on average, customers of Blueprinty have more patents awarded than non-customers.\nThe histogram shows a side-by-side comparison of the number of patents awarded to customers (in blue) and non-customers (in red). Both distributions appear right-skewed, meaning most of the data falls to the left with fewer firms having a high number of patents. These results suggest that firms using Blueprinty’s software have a slightly higher average number of patents compared to those that do not use the software. However, further analysis is needed to determine if this difference is statistically significant and not due to other factors such as firm age or region.\nBlueprinty customers are not selected at random. It may be important to account for systematic differences in the age and regional location of customers vs non-customers.\n\n\n\nWe’ll now compare the regions and ages by customer status to see if there are systematic differences in these variables between customers and non-customers. This can help us understand whether any differences in patent numbers might be influenced by these factors.\n\n# Age comparison by customer status\nplt.figure(figsize=(10, 6))\nsns.boxplot(x='iscustomer', y='age', data=blueprinty)\nplt.title('Age Distribution by Customer Status')\nplt.xlabel('Customer Status')\nplt.ylabel('Age')\nplt.show()\n\n# Calculating the mean age by customer status for interpretation\ncustomer_age_mean = blueprinty[blueprinty['iscustomer'] == 1]['age'].mean()\nnon_customer_age_mean = blueprinty[blueprinty['iscustomer'] == 0]['age'].mean()\nprint(f\"Average age for customers: {customer_age_mean}\")\nprint(f\"Average age for non-customers: {non_customer_age_mean}\")\n\n# Compare regions by customer status using a count plot\nplt.figure(figsize=(12, 6))\nsns.countplot(x='region', hue='iscustomer', data=blueprinty)\nplt.title('Distribution of Firms by Region and Customer Status')\nplt.xlabel('Region')\nplt.ylabel('Count of Firms')\nplt.legend(title='Is Customer', labels=['No', 'Yes'])\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\nAverage age for customers: 24.1497461928934\nAverage age for non-customers: 26.691481197237145\n\n\n\n\n\n\n\n\n\nAge-Related Observations: Younger firms are more likely to be customers of Blueprinty. This could imply that Blueprinty’s software appeals more to newer firms, or that younger firms are more open to adopting new technologies for patent design.\nRegion-Related Observations: The count plot shows the distribution of firms across different regions split by whether they are customers or not. It appears that some regions might have a higher proportion of customers than others, suggesting regional differences in the adoption of Blueprinty’s software.\nThese findings indicate that age and regional location are indeed factors that vary between customers and non-customers. Such differences could potentially confound the analysis of the impact of using Blueprinty’s software on the number of patents awarded. It’s crucial to account for these factors in any further statistical modeling to isolate the effect of the software on patent success.\n\n\n\n\nSince our outcome variable of interest can only be small integer values per a set unit of time, we can use a Poisson density to model the number of patents awarded to each engineering firm over the last 5 years. We start by estimating a simple Poisson model via Maximum Likelihood.\n\n\nFor a random variable \\(Y\\) following a Poisson distribution with a rate parameter \\(\\lambda\\), the probability mass function is given by: \\[\nf(Y|\\lambda) = e^{-\\lambda} \\frac{\\lambda^Y}{Y!}\n\\]\nThe log-likelihood function for \\(Y\\) given \\(\\lambda\\) is: \\[\n\\ell(\\lambda; Y) = \\log(f(Y|\\lambda)) = -\\lambda + Y \\log(\\lambda) - \\log(Y!)\n\\]\n\n\n\n\n\n\nPoisson Log-Likelihood Function Python Code\n\n\n\n\n\n\nimport numpy as np\n\ndef poisson_log_likelihood(lambda_, Y):\n    \"\"\" Calculate the log-likelihood for a Poisson-distributed variable.\n\n    Args:\n    lambda_ (float): The rate parameter of the Poisson distribution.\n    Y (int or np.array): The observed count(s).\n\n    Returns:\n    float: The log-likelihood of observing Y given lambda.\n    \"\"\"\n    if lambda_ &lt;= 0:\n        return -np.inf  # log-likelihood is negative infinity if lambda is not positive\n    return -lambda_ + np.sum(Y * np.log(lambda_)) - np.sum(np.log(np.arange(1, Y+1)))\n\n# Example usage with a sample data point\nsample_Y = 5\nsample_lambda = 4\npoisson_log_likelihood(sample_lambda, sample_Y)\n\n-1.8560199371825927\n\n\nThe log-likelihood value for a sample data point where \\(Y\\) =5 patents and \\(\\lambda\\) = 4 is approximately -1.856. This function is working correctly and can now be used to explore the log-likelihood across a range of values for \\(\\lambda\\).\n\n\n\n\n\n\n\n# Range of lambda values from 0.1 to 10\nlambda_range = np.linspace(0.1, 10, 400)\nlog_likelihood_values = [poisson_log_likelihood(lambda_, sample_Y) for lambda_ in lambda_range]\n\n# Plotting the log-likelihood function\nplt.figure(figsize=(10, 6))\nplt.plot(lambda_range, log_likelihood_values, color='blue')\nplt.title('Log-Likelihood of Poisson Distribution')\nplt.xlabel('Lambda')\nplt.ylabel('Log-Likelihood')\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\nThe plot above shows how the log-likelihood of the Poisson distribution varies with different values of \\(\\lambda\\) for an observed count of 5 patents. The log-likelihood reaches its peak at a certain value of \\(\\lambda\\), suggesting the most probable rate parameter for this data point.\nThe maximum likelihood estimation (MLE) involves differentiating the log-likelihood function with respect to \\(\\lambda\\) and setting the derivative to zero: \\[\n\\frac{d\\ell}{d\\lambda} = -1 + \\frac{Y}{\\lambda} = 0\n\\]\nSolving for \\(\\lambda\\) gives: \\[\n\\lambda = Y\n\\]\nThus, the MLE for \\(\\lambda\\) in a Poisson distribution is the sample mean of \\(Y\\), which is intuitive as the mean of a Poisson distribution is \\(\\lambda\\).\n\n\n\n\nfrom scipy.optimize import minimize_scalar\nfrom scipy.optimize import minimize\nimport scipy.special as sps\nfrom sklearn.preprocessing import StandardScaler\n\ndef total_negative_log_likelihood(lambda_):\n    if lambda_ &lt;= 0:\n        return np.inf  # Return a large number if lambda is not positive\n    # Calculate the total log-likelihood for all data points\n    return -np.sum(-lambda_ + blueprinty['patents'] * np.log(lambda_) - sps.gammaln(blueprinty['patents'] + 1))\n\n# Use minimize_scalar to find the lambda that minimizes the negative log-likelihood\nresult = minimize_scalar(total_negative_log_likelihood, bounds=(0.1, 20), method='bounded')\n\nresult\n\n message: Solution found.\n success: True\n  status: 0\n     fun: 3367.6837722350956\n       x: 3.6846666212927954\n     nit: 12\n    nfev: 12\n\n\nThe optimization process successfully found the maximum likelihood estimate (MLE) for \\(\\lambda\\). The MLE of \\(\\lambda\\), which maximizes the log-likelihood across all patent data points, is approximately 3.685. This suggests that the average rate of patents awarded per firm per 5 years, under the assumption of a Poisson distribution, is about 3.685.\n\n\n\n\nNext, we extend our simple Poisson model to a Poisson Regression Model such that \\(Y_i = \\text{Poisson}(\\lambda_i)\\) where \\(\\lambda_i = \\exp(X_i'\\beta)\\). The interpretation is that the success rate of patent awards is not constant across all firms (\\(\\lambda\\)) but rather is a function of firm characteristics \\(X_i\\). Specifically, we will use the covariates age, age squared, region, and whether the firm is a customer of Blueprinty.\n\ndef poisson_regression_log_likelihood(beta, X, Y):\n    \"\"\"Calculate the log-likelihood for the Poisson regression model.\n    \n    Args:\n        beta (np.array): Coefficients for the regression model.\n        X (np.array): Design matrix containing the covariates for each observation.\n        Y (np.array): The observed counts.\n        \n    Returns:\n        float: The log-likelihood of observing Y given X and beta.\n    \"\"\"\n    linear_pred = np.dot(X, beta)\n    lambda_ = np.exp(linear_pred)\n    log_likelihood = np.sum(-lambda_ + Y * linear_pred - sps.gammaln(Y + 1))\n    return -log_likelihood\n\n\n\n\n\n\n\nMLE for Poisson Regression\n\n\n\n\n\n\n# Add the 'age squared' term to the dataset\nblueprinty['age_squared'] = blueprinty['age'] ** 2\n\n# Encode the 'region' categorical variable into dummy variables\nregion_dummies = pd.get_dummies(blueprinty['region'], drop_first=True)\n\n# Concatenate the original data frame with the new dummy variables\nblueprinty_prepared = pd.concat([blueprinty, region_dummies], axis=1)\n\n# Standardize the continuous predictors: 'age' and 'age squared'\nscaler = StandardScaler()\nblueprinty_prepared[['age', 'age_squared']] = scaler.fit_transform(blueprinty_prepared[['age', 'age_squared']])\n\n# Define the columns to be used in the design matrix\nX_columns = ['age', 'age_squared', 'iscustomer'] + list(region_dummies.columns)\nX = np.column_stack([np.ones(blueprinty_prepared.shape[0]), blueprinty_prepared[X_columns].values])\n\n# Ensure the design matrix X is of a numeric type\nX = X.astype(float)\n\n# Response variable Y - make sure it is an integer since it's count data\nY = blueprinty['patents'].astype(int)\n\n# Initial guess for the beta coefficients\ninitial_beta = np.zeros(X.shape[1])\n\n# Define bounds to ensure coefficients remain within a reasonable range\nbounds = [(None, None) if i == 0 else (-3, 3) for i in range(X.shape[1])]\n\n# Run the minimization procedure\nreg_result = minimize(poisson_regression_log_likelihood, initial_beta, args=(X, Y), method='L-BFGS-B', bounds=bounds)\n\n# Check if the optimization was successful and print the results\nif reg_result.success:\n    print('Optimization was successful.')\n    print('Estimated coefficients:', reg_result.x)\nelse:\n    print('Optimization failed.')\n    print(reg_result)\n\nOptimization was successful.\nEstimated coefficients: [ 1.21543925  1.04657594 -1.14095337  0.11812811  0.09861287 -0.02008799\n  0.05718399  0.05129341]\n\n\n\n\n\n\n# Calculate standard errors from the inverse Hessian\nhessian_inv = reg_result.hess_inv.todense()  # Convert to dense matrix if it's sparse\nstandard_errors = np.sqrt(np.diag(hessian_inv))\n\n# Present a table of coefficients and standard errors\ncoefficients_table = pd.DataFrame({\n    'Coefficient': reg_result.x,\n    'Standard Error': standard_errors\n})\n\nprint(coefficients_table)\n\n   Coefficient  Standard Error\n0     1.215439        0.264755\n1     1.046576        1.366053\n2    -1.140953        1.402167\n3     0.118128        0.651380\n4     0.098613        0.425571\n5    -0.020088        0.650112\n6     0.057184        0.605368\n7     0.051293        0.952206\n\n\nCheck the results using sm.GLM() function._\n\nimport statsmodels.api as sm\n# Create the GLM Poisson model using statsmodels\npoisson_glm = sm.GLM(Y, X, family=sm.families.Poisson())\n\n# Fit the GLM Poisson model\npoisson_results = poisson_glm.fit()\n\n# Print the summary of the GLM Poisson results\npoisson_results.summary()\n\n\n\nGeneralized Linear Model Regression Results\n\n\nDep. Variable:\npatents\nNo. Observations:\n1500\n\n\nModel:\nGLM\nDf Residuals:\n1492\n\n\nModel Family:\nPoisson\nDf Model:\n7\n\n\nLink Function:\nLog\nScale:\n1.0000\n\n\nMethod:\nIRLS\nLog-Likelihood:\n-3275.9\n\n\nDate:\nFri, 03 May 2024\nDeviance:\n2178.8\n\n\nTime:\n15:55:02\nPearson chi2:\n2.11e+03\n\n\nNo. Iterations:\n5\nPseudo R-squ. (CS):\n0.1152\n\n\nCovariance Type:\nnonrobust\n\n\n\n\n\n\n\n\n\ncoef\nstd err\nz\nP&gt;|z|\n[0.025\n0.975]\n\n\nconst\n1.2154\n0.036\n33.368\n0.000\n1.144\n1.287\n\n\nx1\n1.0465\n0.100\n10.414\n0.000\n0.850\n1.243\n\n\nx2\n-1.1408\n0.102\n-11.131\n0.000\n-1.342\n-0.940\n\n\nx3\n0.1181\n0.039\n3.035\n0.002\n0.042\n0.194\n\n\nx4\n0.0986\n0.042\n2.347\n0.019\n0.016\n0.181\n\n\nx5\n-0.0201\n0.054\n-0.374\n0.709\n-0.126\n0.085\n\n\nx6\n0.0572\n0.053\n1.085\n0.278\n-0.046\n0.160\n\n\nx7\n0.0513\n0.047\n1.088\n0.277\n-0.041\n0.144\n\n\n\n\n\n\n\n\n\nBased on the results of the Poisson regression model, we can see that the coefficient for the iscustomer variable x3 (which represents whether a firm is using Blueprinty’s software or not) is 0.118128. The p-value for this coefficient is 0.002, indicating that the effect of Blueprinty’s software on patent success is statistically significant. Since the Poisson regression model uses a log link, the coefficient of 0.118128 means that, holding other variables constant, the expected log count of patents for a customer of Blueprinty is 0.118128 units higher than for a non-customer. \\[\n\\exp(0.118128) \\approx 1.125\n\\] This means that firms using Blueprinty’s software are expected to have about a 12.5% higher count of patents compared to those not using it, when controlling for other factors such as age, age squared, and region.\nThe positive coefficient and its statistical significance suggest that using Blueprinty’s software has a favorable impact on the number of patents awarded to firms, supporting the claim that the software can improve patent application success rates.\nHowever, note that the standard errors for the two methods came out differently, which needs further investigation."
  },
  {
    "objectID": "homeworks/hw2/hw2_questions.html#blueprinty-case-study",
    "href": "homeworks/hw2/hw2_questions.html#blueprinty-case-study",
    "title": "Poisson Regression Examples",
    "section": "",
    "text": "Blueprinty is a small firm that makes software for developing blueprints specifically for submitting patent applications to the US patent office. Their marketing team would like to make the claim that patent applicants using Blueprinty’s software are more successful in getting their patent applications approved. Ideal data to study such an effect might include the success rate of patent applications before using Blueprinty’s software and after using it. unfortunately, such data is not available.\nHowever, Blueprinty has collected data on 1,500 mature (non-startup) engineering firms. The data include each firm’s number of patents awarded over the last 5 years, regional location, age since incorporation, and whether or not the firm uses Blueprinty’s software. The marketing team would like to use this data to make the claim that firms using Blueprinty’s software are more successful in getting their patent applications approved.\n\n\n\n\nimport pandas as pd \n# Load dataset \nblueprinty = pd.read_csv(\"./blueprinty.csv\")\n\n# Summarize data\nblueprinty.describe() \n\n\n\n\n\n\n\n\n\nUnnamed: 0\npatents\nage\niscustomer\n\n\n\n\ncount\n1500.000000\n1500.000000\n1500.000000\n1500.000000\n\n\nmean\n750.500000\n3.684667\n26.357667\n0.131333\n\n\nstd\n433.157015\n2.352500\n7.242528\n0.337877\n\n\nmin\n1.000000\n0.000000\n9.000000\n0.000000\n\n\n25%\n375.750000\n2.000000\n21.000000\n0.000000\n\n\n50%\n750.500000\n3.000000\n26.000000\n0.000000\n\n\n75%\n1125.250000\n5.000000\n31.625000\n0.000000\n\n\nmax\n1500.000000\n16.000000\n49.000000\n1.000000\n\n\n\n\n\n\n\n\n\n\nWe’ll visualize the distributions and calculate the mean number of patents by customer status.\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Calculate the mean number of patents for customers and non-customers\nmean_patents_customers = blueprinty[blueprinty['iscustomer'] == 1]['patents'].mean()\nmean_patents_non_customers = blueprinty[blueprinty['iscustomer'] == 0]['patents'].mean()\n\nprint(f\"Mean number of patents for customers: {mean_patents_customers}\")\nprint(f\"Mean number of patents for non-customers: {mean_patents_non_customers}\")\n\n# Plot histograms\nplt.figure(figsize=(12, 6))\nsns.histplot(blueprinty[blueprinty['iscustomer'] == 1]['patents'], color='blue', label='Customers', kde=False)\nsns.histplot(blueprinty[blueprinty['iscustomer'] == 0]['patents'], color='red', label='Non-Customers', kde=False)\nplt.title('Distribution of Number of Patents Awarded by Customer Status')\nplt.xlabel('Number of Patents Awarded')\nplt.ylabel('Frequency')\nplt.legend()\nplt.show()\n\nMean number of patents for customers: 4.091370558375634\nMean number of patents for non-customers: 3.6231772831926325\n\n\n\n\n\n\n\n\n\nMeans: The mean number of patents for customers is approximately 4.09, which is higher than the mean for non-customers at about 3.62. This suggests that on average, customers of Blueprinty have more patents awarded than non-customers.\nThe histogram shows a side-by-side comparison of the number of patents awarded to customers (in blue) and non-customers (in red). Both distributions appear right-skewed, meaning most of the data falls to the left with fewer firms having a high number of patents. These results suggest that firms using Blueprinty’s software have a slightly higher average number of patents compared to those that do not use the software. However, further analysis is needed to determine if this difference is statistically significant and not due to other factors such as firm age or region.\nBlueprinty customers are not selected at random. It may be important to account for systematic differences in the age and regional location of customers vs non-customers.\n\n\n\nWe’ll now compare the regions and ages by customer status to see if there are systematic differences in these variables between customers and non-customers. This can help us understand whether any differences in patent numbers might be influenced by these factors.\n\n# Age comparison by customer status\nplt.figure(figsize=(10, 6))\nsns.boxplot(x='iscustomer', y='age', data=blueprinty)\nplt.title('Age Distribution by Customer Status')\nplt.xlabel('Customer Status')\nplt.ylabel('Age')\nplt.show()\n\n# Calculating the mean age by customer status for interpretation\ncustomer_age_mean = blueprinty[blueprinty['iscustomer'] == 1]['age'].mean()\nnon_customer_age_mean = blueprinty[blueprinty['iscustomer'] == 0]['age'].mean()\nprint(f\"Average age for customers: {customer_age_mean}\")\nprint(f\"Average age for non-customers: {non_customer_age_mean}\")\n\n# Compare regions by customer status using a count plot\nplt.figure(figsize=(12, 6))\nsns.countplot(x='region', hue='iscustomer', data=blueprinty)\nplt.title('Distribution of Firms by Region and Customer Status')\nplt.xlabel('Region')\nplt.ylabel('Count of Firms')\nplt.legend(title='Is Customer', labels=['No', 'Yes'])\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\nAverage age for customers: 24.1497461928934\nAverage age for non-customers: 26.691481197237145\n\n\n\n\n\n\n\n\n\nAge-Related Observations: Younger firms are more likely to be customers of Blueprinty. This could imply that Blueprinty’s software appeals more to newer firms, or that younger firms are more open to adopting new technologies for patent design.\nRegion-Related Observations: The count plot shows the distribution of firms across different regions split by whether they are customers or not. It appears that some regions might have a higher proportion of customers than others, suggesting regional differences in the adoption of Blueprinty’s software.\nThese findings indicate that age and regional location are indeed factors that vary between customers and non-customers. Such differences could potentially confound the analysis of the impact of using Blueprinty’s software on the number of patents awarded. It’s crucial to account for these factors in any further statistical modeling to isolate the effect of the software on patent success.\n\n\n\n\nSince our outcome variable of interest can only be small integer values per a set unit of time, we can use a Poisson density to model the number of patents awarded to each engineering firm over the last 5 years. We start by estimating a simple Poisson model via Maximum Likelihood.\n\n\nFor a random variable \\(Y\\) following a Poisson distribution with a rate parameter \\(\\lambda\\), the probability mass function is given by: \\[\nf(Y|\\lambda) = e^{-\\lambda} \\frac{\\lambda^Y}{Y!}\n\\]\nThe log-likelihood function for \\(Y\\) given \\(\\lambda\\) is: \\[\n\\ell(\\lambda; Y) = \\log(f(Y|\\lambda)) = -\\lambda + Y \\log(\\lambda) - \\log(Y!)\n\\]\n\n\n\n\n\n\nPoisson Log-Likelihood Function Python Code\n\n\n\n\n\n\nimport numpy as np\n\ndef poisson_log_likelihood(lambda_, Y):\n    \"\"\" Calculate the log-likelihood for a Poisson-distributed variable.\n\n    Args:\n    lambda_ (float): The rate parameter of the Poisson distribution.\n    Y (int or np.array): The observed count(s).\n\n    Returns:\n    float: The log-likelihood of observing Y given lambda.\n    \"\"\"\n    if lambda_ &lt;= 0:\n        return -np.inf  # log-likelihood is negative infinity if lambda is not positive\n    return -lambda_ + np.sum(Y * np.log(lambda_)) - np.sum(np.log(np.arange(1, Y+1)))\n\n# Example usage with a sample data point\nsample_Y = 5\nsample_lambda = 4\npoisson_log_likelihood(sample_lambda, sample_Y)\n\n-1.8560199371825927\n\n\nThe log-likelihood value for a sample data point where \\(Y\\) =5 patents and \\(\\lambda\\) = 4 is approximately -1.856. This function is working correctly and can now be used to explore the log-likelihood across a range of values for \\(\\lambda\\).\n\n\n\n\n\n\n\n# Range of lambda values from 0.1 to 10\nlambda_range = np.linspace(0.1, 10, 400)\nlog_likelihood_values = [poisson_log_likelihood(lambda_, sample_Y) for lambda_ in lambda_range]\n\n# Plotting the log-likelihood function\nplt.figure(figsize=(10, 6))\nplt.plot(lambda_range, log_likelihood_values, color='blue')\nplt.title('Log-Likelihood of Poisson Distribution')\nplt.xlabel('Lambda')\nplt.ylabel('Log-Likelihood')\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\nThe plot above shows how the log-likelihood of the Poisson distribution varies with different values of \\(\\lambda\\) for an observed count of 5 patents. The log-likelihood reaches its peak at a certain value of \\(\\lambda\\), suggesting the most probable rate parameter for this data point.\nThe maximum likelihood estimation (MLE) involves differentiating the log-likelihood function with respect to \\(\\lambda\\) and setting the derivative to zero: \\[\n\\frac{d\\ell}{d\\lambda} = -1 + \\frac{Y}{\\lambda} = 0\n\\]\nSolving for \\(\\lambda\\) gives: \\[\n\\lambda = Y\n\\]\nThus, the MLE for \\(\\lambda\\) in a Poisson distribution is the sample mean of \\(Y\\), which is intuitive as the mean of a Poisson distribution is \\(\\lambda\\).\n\n\n\n\nfrom scipy.optimize import minimize_scalar\nfrom scipy.optimize import minimize\nimport scipy.special as sps\nfrom sklearn.preprocessing import StandardScaler\n\ndef total_negative_log_likelihood(lambda_):\n    if lambda_ &lt;= 0:\n        return np.inf  # Return a large number if lambda is not positive\n    # Calculate the total log-likelihood for all data points\n    return -np.sum(-lambda_ + blueprinty['patents'] * np.log(lambda_) - sps.gammaln(blueprinty['patents'] + 1))\n\n# Use minimize_scalar to find the lambda that minimizes the negative log-likelihood\nresult = minimize_scalar(total_negative_log_likelihood, bounds=(0.1, 20), method='bounded')\n\nresult\n\n message: Solution found.\n success: True\n  status: 0\n     fun: 3367.6837722350956\n       x: 3.6846666212927954\n     nit: 12\n    nfev: 12\n\n\nThe optimization process successfully found the maximum likelihood estimate (MLE) for \\(\\lambda\\). The MLE of \\(\\lambda\\), which maximizes the log-likelihood across all patent data points, is approximately 3.685. This suggests that the average rate of patents awarded per firm per 5 years, under the assumption of a Poisson distribution, is about 3.685.\n\n\n\n\nNext, we extend our simple Poisson model to a Poisson Regression Model such that \\(Y_i = \\text{Poisson}(\\lambda_i)\\) where \\(\\lambda_i = \\exp(X_i'\\beta)\\). The interpretation is that the success rate of patent awards is not constant across all firms (\\(\\lambda\\)) but rather is a function of firm characteristics \\(X_i\\). Specifically, we will use the covariates age, age squared, region, and whether the firm is a customer of Blueprinty.\n\ndef poisson_regression_log_likelihood(beta, X, Y):\n    \"\"\"Calculate the log-likelihood for the Poisson regression model.\n    \n    Args:\n        beta (np.array): Coefficients for the regression model.\n        X (np.array): Design matrix containing the covariates for each observation.\n        Y (np.array): The observed counts.\n        \n    Returns:\n        float: The log-likelihood of observing Y given X and beta.\n    \"\"\"\n    linear_pred = np.dot(X, beta)\n    lambda_ = np.exp(linear_pred)\n    log_likelihood = np.sum(-lambda_ + Y * linear_pred - sps.gammaln(Y + 1))\n    return -log_likelihood\n\n\n\n\n\n\n\nMLE for Poisson Regression\n\n\n\n\n\n\n# Add the 'age squared' term to the dataset\nblueprinty['age_squared'] = blueprinty['age'] ** 2\n\n# Encode the 'region' categorical variable into dummy variables\nregion_dummies = pd.get_dummies(blueprinty['region'], drop_first=True)\n\n# Concatenate the original data frame with the new dummy variables\nblueprinty_prepared = pd.concat([blueprinty, region_dummies], axis=1)\n\n# Standardize the continuous predictors: 'age' and 'age squared'\nscaler = StandardScaler()\nblueprinty_prepared[['age', 'age_squared']] = scaler.fit_transform(blueprinty_prepared[['age', 'age_squared']])\n\n# Define the columns to be used in the design matrix\nX_columns = ['age', 'age_squared', 'iscustomer'] + list(region_dummies.columns)\nX = np.column_stack([np.ones(blueprinty_prepared.shape[0]), blueprinty_prepared[X_columns].values])\n\n# Ensure the design matrix X is of a numeric type\nX = X.astype(float)\n\n# Response variable Y - make sure it is an integer since it's count data\nY = blueprinty['patents'].astype(int)\n\n# Initial guess for the beta coefficients\ninitial_beta = np.zeros(X.shape[1])\n\n# Define bounds to ensure coefficients remain within a reasonable range\nbounds = [(None, None) if i == 0 else (-3, 3) for i in range(X.shape[1])]\n\n# Run the minimization procedure\nreg_result = minimize(poisson_regression_log_likelihood, initial_beta, args=(X, Y), method='L-BFGS-B', bounds=bounds)\n\n# Check if the optimization was successful and print the results\nif reg_result.success:\n    print('Optimization was successful.')\n    print('Estimated coefficients:', reg_result.x)\nelse:\n    print('Optimization failed.')\n    print(reg_result)\n\nOptimization was successful.\nEstimated coefficients: [ 1.21543925  1.04657594 -1.14095337  0.11812811  0.09861287 -0.02008799\n  0.05718399  0.05129341]\n\n\n\n\n\n\n# Calculate standard errors from the inverse Hessian\nhessian_inv = reg_result.hess_inv.todense()  # Convert to dense matrix if it's sparse\nstandard_errors = np.sqrt(np.diag(hessian_inv))\n\n# Present a table of coefficients and standard errors\ncoefficients_table = pd.DataFrame({\n    'Coefficient': reg_result.x,\n    'Standard Error': standard_errors\n})\n\nprint(coefficients_table)\n\n   Coefficient  Standard Error\n0     1.215439        0.264755\n1     1.046576        1.366053\n2    -1.140953        1.402167\n3     0.118128        0.651380\n4     0.098613        0.425571\n5    -0.020088        0.650112\n6     0.057184        0.605368\n7     0.051293        0.952206\n\n\nCheck the results using sm.GLM() function._\n\nimport statsmodels.api as sm\n# Create the GLM Poisson model using statsmodels\npoisson_glm = sm.GLM(Y, X, family=sm.families.Poisson())\n\n# Fit the GLM Poisson model\npoisson_results = poisson_glm.fit()\n\n# Print the summary of the GLM Poisson results\npoisson_results.summary()\n\n\n\nGeneralized Linear Model Regression Results\n\n\nDep. Variable:\npatents\nNo. Observations:\n1500\n\n\nModel:\nGLM\nDf Residuals:\n1492\n\n\nModel Family:\nPoisson\nDf Model:\n7\n\n\nLink Function:\nLog\nScale:\n1.0000\n\n\nMethod:\nIRLS\nLog-Likelihood:\n-3275.9\n\n\nDate:\nFri, 03 May 2024\nDeviance:\n2178.8\n\n\nTime:\n15:55:02\nPearson chi2:\n2.11e+03\n\n\nNo. Iterations:\n5\nPseudo R-squ. (CS):\n0.1152\n\n\nCovariance Type:\nnonrobust\n\n\n\n\n\n\n\n\n\ncoef\nstd err\nz\nP&gt;|z|\n[0.025\n0.975]\n\n\nconst\n1.2154\n0.036\n33.368\n0.000\n1.144\n1.287\n\n\nx1\n1.0465\n0.100\n10.414\n0.000\n0.850\n1.243\n\n\nx2\n-1.1408\n0.102\n-11.131\n0.000\n-1.342\n-0.940\n\n\nx3\n0.1181\n0.039\n3.035\n0.002\n0.042\n0.194\n\n\nx4\n0.0986\n0.042\n2.347\n0.019\n0.016\n0.181\n\n\nx5\n-0.0201\n0.054\n-0.374\n0.709\n-0.126\n0.085\n\n\nx6\n0.0572\n0.053\n1.085\n0.278\n-0.046\n0.160\n\n\nx7\n0.0513\n0.047\n1.088\n0.277\n-0.041\n0.144\n\n\n\n\n\n\n\n\n\nBased on the results of the Poisson regression model, we can see that the coefficient for the iscustomer variable x3 (which represents whether a firm is using Blueprinty’s software or not) is 0.118128. The p-value for this coefficient is 0.002, indicating that the effect of Blueprinty’s software on patent success is statistically significant. Since the Poisson regression model uses a log link, the coefficient of 0.118128 means that, holding other variables constant, the expected log count of patents for a customer of Blueprinty is 0.118128 units higher than for a non-customer. \\[\n\\exp(0.118128) \\approx 1.125\n\\] This means that firms using Blueprinty’s software are expected to have about a 12.5% higher count of patents compared to those not using it, when controlling for other factors such as age, age squared, and region.\nThe positive coefficient and its statistical significance suggest that using Blueprinty’s software has a favorable impact on the number of patents awarded to firms, supporting the claim that the software can improve patent application success rates.\nHowever, note that the standard errors for the two methods came out differently, which needs further investigation."
  },
  {
    "objectID": "homeworks/hw2/hw2_questions.html#airbnb-case-study",
    "href": "homeworks/hw2/hw2_questions.html#airbnb-case-study",
    "title": "Poisson Regression Examples",
    "section": "AirBnB Case Study",
    "text": "AirBnB Case Study\n\nIntroduction\nAirBnB is a popular platform for booking short-term rentals. In March 2017, students Annika Awad, Evan Lebo, and Anna Linden scraped of 40,000 Airbnb listings from New York City. The data include the following variables:\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n- `id` = unique ID number for each unit\n- `last_scraped` = date when information scraped\n- `host_since` = date when host first listed the unit on Airbnb\n- `days` = `last_scraped` - `host_since` = number of days the unit has been listed\n- `room_type` = Entire home/apt., Private room, or Shared room\n- `bathrooms` = number of bathrooms\n- `bedrooms` = number of bedrooms\n- `price` = price per night (dollars)\n- `number_of_reviews` = number of reviews for the unit on Airbnb\n- `review_scores_cleanliness` = a cleanliness score from reviews (1-10)\n- `review_scores_location` = a \"quality of location\" score from reviews (1-10)\n- `review_scores_value` = a \"quality of value\" score from reviews (1-10)\n- `instant_bookable` = \"t\" if instantly bookable, \"f\" if not\n\n\n\n\n\nData Preparation\n\nimport pandas as pd \n\nabnb = pd.read_csv('./airbnb.csv')\nabnb.describe()\n\n\n\n\n\n\n\n\n\nUnnamed: 0\nid\ndays\nbathrooms\nbedrooms\nprice\nnumber_of_reviews\nreview_scores_cleanliness\nreview_scores_location\nreview_scores_value\n\n\n\n\ncount\n40628.000000\n4.062800e+04\n40628.000000\n40468.000000\n40552.000000\n40628.000000\n40628.000000\n30433.000000\n30374.000000\n30372.000000\n\n\nmean\n20314.500000\n9.698889e+06\n1102.368219\n1.124592\n1.147046\n144.760732\n15.904426\n9.198370\n9.413544\n9.331522\n\n\nstd\n11728.437705\n5.460166e+06\n1383.269358\n0.385884\n0.691746\n210.657597\n29.246009\n1.119935\n0.844949\n0.902966\n\n\nmin\n1.000000\n2.515000e+03\n1.000000\n0.000000\n0.000000\n10.000000\n0.000000\n2.000000\n2.000000\n2.000000\n\n\n25%\n10157.750000\n4.889868e+06\n542.000000\n1.000000\n1.000000\n70.000000\n1.000000\n9.000000\n9.000000\n9.000000\n\n\n50%\n20314.500000\n9.862878e+06\n996.000000\n1.000000\n1.000000\n100.000000\n4.000000\n10.000000\n10.000000\n10.000000\n\n\n75%\n30471.250000\n1.466789e+07\n1535.000000\n1.000000\n1.000000\n170.000000\n17.000000\n10.000000\n10.000000\n10.000000\n\n\nmax\n40628.000000\n1.800967e+07\n42828.000000\n8.000000\n10.000000\n10000.000000\n421.000000\n10.000000\n10.000000\n10.000000\n\n\n\n\n\n\n\n\nAs shown above,the dataset covers a broad range of days for which units have been listed (from 1 to 42,828 days), prices range from $10 to $10,000, and the number of reviews varies widely from 0 to 421.\n\nHandle missing values.\nThere are missing values in ‘bathrooms’, ‘bedrooms’, ‘review_scores_cleanliness’, ‘review_scores_location’, and ‘review_scores_value’.\n\nabnb.isnull().sum()\n\nUnnamed: 0                       0\nid                               0\ndays                             0\nlast_scraped                     0\nhost_since                      35\nroom_type                        0\nbathrooms                      160\nbedrooms                        76\nprice                            0\nnumber_of_reviews                0\nreview_scores_cleanliness    10195\nreview_scores_location       10254\nreview_scores_value          10256\ninstant_bookable                 0\ndtype: int64\n\n\n\n# Find room type with missing values in bathrooms \nabnb[abnb['bathrooms'].isnull()]['room_type'].value_counts() \n\n# Find the most common bathroom count for each room type category\ncommon_bathrooms_per_room_type = abnb.groupby('room_type')['bathrooms'].agg(lambda x: x.mode()[0])\ncommon_bathrooms_per_room_type\n\nroom_type\nEntire home/apt    1.0\nPrivate room       1.0\nShared room        1.0\nName: bathrooms, dtype: float64\n\n\nThe most common number of bathrooms for each room type is 1.0, regardless of whether it’s an entire home/apt, a private room, or a shared room.\nGiven this uniformity, we can impute the missing bathroom values with 1.0 for all missing entries across different room types.\n\n# Impute missing bathroom values with the most common bathroom count for each room type\nabnb['bathrooms'] = abnb.apply(\n    lambda row: common_bathrooms_per_room_type[row['room_type']] if pd.isnull(row['bathrooms']) else row['bathrooms'],\n    axis=1\n)\n\nWe use a similar strategy as above, imputing missing values based on the median or mode within each room type category, as this could reflect the typical values more accurately for different types of listings.\n\n\n\n\n\n\nSimilar approach for bedrooms and scores of cleanliness, location, and value\n\n\n\n\n\n\n# Similar approach for bedrooms missing values \ncommon_bedrooms_per_room_type = abnb.groupby('room_type')['bedrooms'].agg(lambda x: x.mode()[0])\n\n# Display the most common number of bedrooms per room type\ncommon_bedrooms_per_room_type\n\n# Impute missing bedroom values with the most common bedroom count for each room type\nabnb['bedrooms'] = abnb.apply(\n    lambda row: common_bedrooms_per_room_type[row['room_type']] if pd.isnull(row['bedrooms']) else row['bedrooms'],\n    axis=1\n)\n\n# Calculate median review scores for cleanliness, location, and value for each room type category\nmedian_review_scores_per_room_type = abnb.groupby('room_type')[['review_scores_cleanliness', 'review_scores_location', 'review_scores_value']].median()\n\n# Display the median review scores per room type\nmedian_review_scores_per_room_type\n\n# Impute missing review scores with the median values for each room type\nfor score_type in ['review_scores_cleanliness', 'review_scores_location', 'review_scores_value']:\n    abnb[score_type] = abnb.apply(\n        lambda row: median_review_scores_per_room_type.loc[row['room_type'], score_type] if pd.isnull(row[score_type]) else row[score_type],\n        axis=1\n    )\n\n# Check if there are any missing values left in the review scores columns\nabnb.isnull().sum()\n\nUnnamed: 0                    0\nid                            0\ndays                          0\nlast_scraped                  0\nhost_since                   35\nroom_type                     0\nbathrooms                     0\nbedrooms                      0\nprice                         0\nnumber_of_reviews             0\nreview_scores_cleanliness     0\nreview_scores_location        0\nreview_scores_value           0\ninstant_bookable              0\ndtype: int64\n\n\n\n\n\nNote: missing values for ‘host_since’ is not handled as ‘days’ for each listing has no missing values, we can use this variable for later analysis since ‘days’ = ‘last_scraped’ - ‘host_since’.\n\n\n\nData visualization\nNow, let’s create some visualizations to explore the dataset further.\n\n# Create a figure for multiple histograms\nfig, axes = plt.subplots(3, 1, figsize=(10, 15))\n\n# Histogram of prices\nsns.histplot(abnb['price'], bins=100, ax=axes[0], color='skyblue')\naxes[0].set_title('Distribution of Prices')\naxes[0].set_xlabel('Price')\naxes[0].set_ylabel('Frequency')\n#axes[0].set_xlim(0, 1000) \n\n# Histogram of number of reviews\nsns.histplot(abnb['number_of_reviews'], bins=50, ax=axes[1], color='lightgreen')\naxes[1].set_title('Distribution of Number of Reviews')\naxes[1].set_xlabel('Number of Reviews')\naxes[1].set_ylabel('Frequency')\naxes[1].set_xlim(0, 300)  \n\n# Histogram of days listed, \nsns.histplot(abnb['days'], bins=300, ax=axes[2], color='salmon')\naxes[2].set_title('Distribution of Days Listed')\naxes[2].set_xlabel('Days')\naxes[2].set_ylabel('Frequency')\naxes[2].set_xlim(0, 5000)  \n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nDistribution of Prices: The majority of listings are priced under $1,000 per night, with a noticeable peak around the lower price range. There are a few listings with very high prices, which appear as outliers.\nDistribution of Number of Reviews: This distribution is highly skewed to the right, showing that most listings have a relatively low number of reviews, while a few listings have a very high number of reviews.\nDistribution of Days Listed: Similar to the number of reviews, the days listed are also skewed right, with many listings being relatively new and fewer listings having been available for a long time.\n\nNext, let’s create box plots to examine the distribution of prices and number of reviews across different room types.\n\n# Create a figure for box plots\nfig, axes = plt.subplots(2, 1, figsize=(10, 12))\n\n# Box plot of prices by room type\nsns.boxplot(x='room_type', y='price', data=abnb, ax=axes[0])\naxes[0].set_title('Price Distribution by Room Type')\naxes[0].set_xlabel('Room Type')\naxes[0].set_ylabel('Price')\naxes[0].set_yscale('log')  # Use logarithmic scale to better display the wide range of prices\n\n# Box plot of number of reviews by room type\nsns.boxplot(x='room_type', y='number_of_reviews', data=abnb, ax=axes[1])\naxes[1].set_title('Number of Reviews Distribution by Room Type')\naxes[1].set_xlabel('Room Type')\naxes[1].set_ylabel('Number of Reviews')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nPrice Distribution by Room Type: The log scale on the y-axis helps in visualizing the wide range of prices across different room types. Entire homes/apartments generally have a higher price range compared to private and shared rooms. There are several outliers indicating some extremely high-priced listings.\nNumber of Reviews Distribution by Room Type: The number of reviews also varies by room type. Entire homes/apartments and private rooms show a closer range of reviews, with entire homes/apartments slightly higher. Shared rooms generally have fewer reviews, which might indicate less usage or fewer bookings.\n\nWe can also vistualize the prices & number of reviews across different room types.\n\n# %%\n# Create a figure for histograms of prices and number of reviews across different room types\nfig, axes = plt.subplots(2, 1, figsize=(10, 12))\n\n# Histogram of prices across room types\nsns.histplot(abnb, x='price', hue='room_type', element='step', palette='pastel', ax=axes[0], bins=50, common_norm=False)\naxes[0].set_title('Histogram of Prices by Room Type')\naxes[0].set_xlabel('Price')\naxes[0].set_ylabel('Density')\naxes[0].set_xlim(0, 1000)  # Limiting x-axis for better visualization\n\n# Histogram of number of reviews across room types\nsns.histplot(abnb, x='number_of_reviews', hue='room_type', element='step', palette='pastel', ax=axes[1], bins=50, common_norm=False)\naxes[1].set_title('Histogram of Number of Reviews by Room Type')\naxes[1].set_xlabel('Number of Reviews')\naxes[1].set_ylabel('Density')\naxes[1].set_xlim(0, 100)  # Limiting x-axis for better visualization\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nModeling\nNow using Poisson regression model to understand the relationship between number of reviews vs. other variables. We will use ‘number_of_reviews’ as the proxy of the number of bookings.\n\nimport statsmodels.api as sm\n\n# Convert categorical variables to dummy variables\nabnb = pd.get_dummies(abnb, columns=['room_type', 'instant_bookable'], drop_first=True)\n\n# Convert necessary columns to float\ncolumns_to_convert = ['room_type_Private room', 'room_type_Shared room', 'instant_bookable_t'] \nabnb[columns_to_convert] = abnb[columns_to_convert].astype(float)\n\n# Define predictors and response variable\nX = abnb[['price', 'days', 'review_scores_cleanliness', 'review_scores_location', 'review_scores_value', \n                 'room_type_Private room', 'room_type_Shared room', 'instant_bookable_t']]\ny = abnb['number_of_reviews']\n\n# Add a constant to the model (intercept)\nX = sm.add_constant(X)\n\n# Build the Poisson regression model on the entire dataset\npoisson_model = sm.GLM(y, X, family=sm.families.Poisson()).fit()\n\n# Display the model summary to see the coefficients and statistical significance\nprint(poisson_model.summary())\n\n                 Generalized Linear Model Regression Results                  \n==============================================================================\nDep. Variable:      number_of_reviews   No. Observations:                40628\nModel:                            GLM   Df Residuals:                    40619\nModel Family:                 Poisson   Df Model:                            8\nLink Function:                    Log   Scale:                          1.0000\nMethod:                          IRLS   Log-Likelihood:            -6.9645e+05\nDate:                Fri, 03 May 2024   Deviance:                   1.2689e+06\nTime:                        15:55:05   Pearson chi2:                 2.03e+06\nNo. Iterations:                    11   Pseudo R-squ. (CS):             0.8294\nCovariance Type:            nonrobust                                         \n=============================================================================================\n                                coef    std err          z      P&gt;|z|      [0.025      0.975]\n---------------------------------------------------------------------------------------------\nconst                         4.7941      0.014    338.482      0.000       4.766       4.822\nprice                        -0.0002   9.43e-06    -21.720      0.000      -0.000      -0.000\ndays                       5.021e-05   3.55e-07    141.541      0.000    4.95e-05    5.09e-05\nreview_scores_cleanliness     0.1012      0.001     68.005      0.000       0.098       0.104\nreview_scores_location       -0.2729      0.002   -181.217      0.000      -0.276      -0.270\nreview_scores_value          -0.0448      0.002    -25.084      0.000      -0.048      -0.041\nroom_type_Private room       -0.1307      0.003    -46.329      0.000      -0.136      -0.125\nroom_type_Shared room        -0.4735      0.009    -54.961      0.000      -0.490      -0.457\ninstant_bookable_t            0.3538      0.003    123.095      0.000       0.348       0.359\n=============================================================================================\n\n\nModel Output Analysis:\n1. Intercept (const): Coefficient: 4.7941. This is the logarithm of the expected count of reviews when all other predictors are zero (base level or baseline scenario).\n\nPredictors Analysis\n\n\nPrice: Coefficient of -0.0002 suggests that as the price increases by one unit, the expected count of reviews decreases slightly, indicating potentially fewer bookings or lesser popularity as prices go up.\n\nDays: Coefficient of 5.02e-05 indicates that listings available for more days have slightly more reviews. This indicates that longer-listed properties tend to accumulate more reviews over time.\nReview Scores\nCleanliness: Higher cleanliness scores positively impact the number of reviews. A one-unit increase in the cleanliness score is associated with about a 10.7% increase in the expected count of reviews, suggesting that cleaner listings receive more reviews.\n\nLocation: -0.2729: Surprisingly, this coefficient is negative, which would imply that better location scores could decrease the number of reviews. This might require further investigation as it’s counterintuitive; typically, one would expect better locations to attract more reviews.\n\nValue: Lower value scores decrease the number of reviews, indicating that guests are less likely to leave a review if they feel the listing does not provide good value.\nRoom Types\nPrivate room: Negative coefficient (-0.1307) compared to the baseline (Entire home/apt), suggesting they are less popular or receive fewer bookings.\n\nShared room: More significant negative coefficient (-0.4375) indicating even fewer reviews, which might reflect less popularity or lower booking rates.\n\nInstant Bookable: Positive coefficient (0.3538) indicating that listings that can be booked instantly tend to have more reviews, possibly due to ease of booking.\n\n\nModel Fit:\nPseudo R-squared (0.8294): suggests a good fit of the model to the data.\n\n\nConclusion\nThe model provides insights into factors that influence guest interaction and feedback on Airbnb listings. Notably, pricing strategy, listing cleanliness, and instant bookability appear to significantly impact the number of reviews a listing receives. The negative coefficients for location and value scores may need further exploration or data validation to understand the context better.\nThis analysis helps in understanding how different aspects of an Airbnb listing affect its popularity and customer feedback, which can be crucial for hosts looking to improve their listings and for Airbnb to guide policy adjustments or feature enhancements."
  },
  {
    "objectID": "homeworks/hw1/hw1_questions.html#conclusion",
    "href": "homeworks/hw1/hw1_questions.html#conclusion",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Conclusion",
    "text": "Conclusion\nThroughout this analysis, we’ve engaged with a dataset that details the effects of matched donations on charitable giving, replicating and interpreting the findings of the study.\nThe original study’s conclusion that match offers increase the likelihood of donating holds true. However, the effectiveness of different match sizes appears to have a ceiling effect, where increasing the match ratio above 1:1 offers no additional advantage. The amount donated seems to be independent of the match offer, indicating that once individuals decide to donate, their generosity is not swayed by the leverage of their donation being matched.\nOur exploration using simulation provided a practical demonstration of statistical theorems and reinforced the original findings. The importance of such matching schemes in fundraising efforts is clear—they are effective at increasing participation rates in charitable giving, but the complexity of the matching offer does not significantly impact the donation behavior among those who decide to give."
  },
  {
    "objectID": "homeworks/hw3/hw3_questions.html",
    "href": "homeworks/hw3/hw3_questions.html",
    "title": "Multinomial logit (MNL) models",
    "section": "",
    "text": "This assignment uses the Multinomial logit (MNL) model to analyze (1) yogurt purchase data made by consumers at a retail location, and (2) conjoint data about consumer preferences for minivans."
  },
  {
    "objectID": "homeworks/hw3/hw3_questions.html#estimating-yogurt-preferences",
    "href": "homeworks/hw3/hw3_questions.html#estimating-yogurt-preferences",
    "title": "Multinomial logit (MNL) models",
    "section": "1. Estimating Yogurt Preferences",
    "text": "1. Estimating Yogurt Preferences\n\nLikelihood for the Multi-nomial Logit (MNL) Model\nSuppose we have \\(i=1,\\ldots,n\\) consumers who each select exactly one product \\(j\\) from a set of \\(J\\) products. The outcome variable is the identity of the product chosen \\(y_i \\in \\{1, \\ldots, J\\}\\) or equivalently a vector of \\(J-1\\) zeros and \\(1\\) one, where the \\(1\\) indicates the selected product. For example, if the third product was chosen out of 4 products, then either \\(y=3\\) or \\(y=(0,0,1,0)\\) depending on how we want to represent it. Suppose also that we have a vector of data on each product \\(x_j\\) (eg, size, price, etc.).\nWe model the consumer’s decision as the selection of the product that provides the most utility, and we’ll specify the utility function as a linear function of the product characteristics:\n\\[ U_{ij} = x_j'\\beta + \\epsilon_{ij} \\]\nwhere \\(\\epsilon_{ij}\\) is an i.i.d. extreme value error term.\nThe choice of the i.i.d. extreme value error term leads to a closed-form expression for the probability that consumer \\(i\\) chooses product \\(j\\):\n\\[ \\mathbb{P}_i(j) = \\frac{e^{x_j'\\beta}}{\\sum_{k=1}^Je^{x_k'\\beta}} \\]\nFor example, if there are 4 products, the probability that consumer \\(i\\) chooses product 3 is:\n\\[ \\mathbb{P}_i(3) = \\frac{e^{x_3'\\beta}}{e^{x_1'\\beta} + e^{x_2'\\beta} + e^{x_3'\\beta} + e^{x_4'\\beta}} \\]\nA clever way to write the individual likelihood function for consumer \\(i\\) is the product of the \\(J\\) probabilities, each raised to the power of an indicator variable (\\(\\delta_{ij}\\)) that indicates the chosen product:\n\\[ L_i(\\beta) = \\prod_{j=1}^J \\mathbb{P}_i(j)^{\\delta_{ij}} = \\mathbb{P}_i(1)^{\\delta_{i1}} \\times \\ldots \\times \\mathbb{P}_i(J)^{\\delta_{iJ}}\\]\nNotice that if the consumer selected product \\(j=3\\), then \\(\\delta_{i3}=1\\) while \\(\\delta_{i1}=\\delta_{i2}=\\delta_{i4}=0\\) and the likelihood is:\n\\[ L_i(\\beta) = \\mathbb{P}_i(1)^0 \\times \\mathbb{P}_i(2)^0 \\times \\mathbb{P}_i(3)^1 \\times \\mathbb{P}_i(4)^0 = \\mathbb{P}_i(3) = \\frac{e^{x_3'\\beta}}{\\sum_{k=1}^Je^{x_k'\\beta}} \\]\nThe joint likelihood (across all consumers) is the product of the \\(n\\) individual likelihoods:\n\\[ L_n(\\beta) = \\prod_{i=1}^n L_i(\\beta) = \\prod_{i=1}^n \\prod_{j=1}^J \\mathbb{P}_i(j)^{\\delta_{ij}} \\]\nAnd the joint log-likelihood function is:\n\\[ \\ell_n(\\beta) = \\sum_{i=1}^n \\sum_{j=1}^J \\delta_{ij} \\log(\\mathbb{P}_i(j)) \\]\n\n\nYogurt Dataset\nWe will use the yogurt_data dataset, which provides anonymized consumer identifiers (id), a vector indicating the chosen product (y1:y4), a vector indicating if any products were “featured” in the store as a form of advertising (f1:f4), and the products’ prices (p1:p4). For example, consumer 1 purchased yogurt 4 at a price of 0.079/oz and none of the yogurts were featured/advertised at the time of consumer 1’s purchase. Consumers 2 through 7 each bought yogurt 2, etc.\n\nDataset\n\nimport pandas as pd\nimport numpy as np \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy.optimize import minimize\n\n# Import the data and show the first few rows\nyogurt = pd.read_csv('./yogurt_data.csv')\nprint(yogurt.head()) \nprint(yogurt.describe())\n\n   id  y1  y2  y3  y4  f1  f2  f3  f4     p1     p2     p3     p4\n0   1   0   0   0   1   0   0   0   0  0.108  0.081  0.061  0.079\n1   2   0   1   0   0   0   0   0   0  0.108  0.098  0.064  0.075\n2   3   0   1   0   0   0   0   0   0  0.108  0.098  0.061  0.086\n3   4   0   1   0   0   0   0   0   0  0.108  0.098  0.061  0.086\n4   5   0   1   0   0   0   0   0   0  0.125  0.098  0.049  0.079\n              id           y1           y2           y3           y4  \\\ncount  2430.0000  2430.000000  2430.000000  2430.000000  2430.000000   \nmean   1215.5000     0.341975     0.401235     0.029218     0.227572   \nstd     701.6249     0.474469     0.490249     0.168452     0.419351   \nmin       1.0000     0.000000     0.000000     0.000000     0.000000   \n25%     608.2500     0.000000     0.000000     0.000000     0.000000   \n50%    1215.5000     0.000000     0.000000     0.000000     0.000000   \n75%    1822.7500     1.000000     1.000000     0.000000     0.000000   \nmax    2430.0000     1.000000     1.000000     1.000000     1.000000   \n\n                f1           f2           f3           f4           p1  \\\ncount  2430.000000  2430.000000  2430.000000  2430.000000  2430.000000   \nmean      0.055556     0.039506     0.037449     0.037449     0.106248   \nstd       0.229109     0.194836     0.189897     0.189897     0.020587   \nmin       0.000000     0.000000     0.000000     0.000000    -0.012000   \n25%       0.000000     0.000000     0.000000     0.000000     0.103000   \n50%       0.000000     0.000000     0.000000     0.000000     0.108000   \n75%       0.000000     0.000000     0.000000     0.000000     0.115000   \nmax       1.000000     1.000000     1.000000     1.000000     0.193000   \n\n                p2           p3           p4  \ncount  2430.000000  2430.000000  2430.000000  \nmean      0.081532     0.053622     0.079507  \nstd       0.011047     0.008054     0.007714  \nmin       0.000000     0.025000     0.004000  \n25%       0.081000     0.050000     0.079000  \n50%       0.086000     0.054000     0.079000  \n75%       0.086000     0.061000     0.086000  \nmax       0.111000     0.086000     0.104000  \n\n\n\n\nVisualizing\n\nprice_columns = ['p1', 'p2', 'p3', 'p4']\n\n# Plot histograms for prices of each product\nfig, axes = plt.subplots(2, 2, figsize=(12, 8), sharey=True)\nfig.suptitle('Price Distributions for Each Product')\n\nsns.histplot(yogurt['p1'], bins=20, kde=True, ax=axes[0, 0])\naxes[0, 0].set_title('Product 1')\n\nsns.histplot(yogurt['p2'], bins=20, kde=True, ax=axes[0, 1])\naxes[0, 1].set_title('Product 2')\n\nsns.histplot(yogurt['p3'], bins=20, kde=True, ax=axes[1, 0])\naxes[1, 0].set_title('Product 3')\n\nsns.histplot(yogurt['p4'], bins=20, kde=True, ax=axes[1, 1])\naxes[1, 1].set_title('Product 4')\n\nplt.tight_layout()\nplt.show()\n\n# Plot boxplots for prices of each product\nplt.figure(figsize=(10, 6))\nsns.boxplot(data=yogurt[price_columns])\nplt.title('Boxplot of Prices for Each Product')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBased on the plots, we can see that:\n\nConsistency: Product 1 has the most consistent pricing, with prices mostly around $0.125.\nLow Price Strategy: Product 3 generally has the lowest prices but shows more variability, possibly indicating different pricing tiers or promotional strategies.\nMiddle Ground: Products 2 and 4 have similar pricing strategies, both centered around $0.08, suggesting they might be positioned similarly in the market.\nOutliers: The presence of lower-priced outliers across all products could indicate promotional pricing or discounts. Product 1 also has a higher outlier, suggesting occasional premium pricing.”\n\n\n\nData Preparation\nNow, let the vector of product features include brand dummy variables for yogurts 1-3 (we’ll omit a dummy for product 4 to avoid multi-collinearity), a dummy variable to indicate if a yogurt was featured, and a continuous variable for the yogurts’ prices:\n\\[ x_j' = [\\mathbbm{1}(\\text{Yogurt 1}), \\mathbbm{1}(\\text{Yogurt 2}), \\mathbbm{1}(\\text{Yogurt 3}), X_f, X_p] \\]\nThe “hard part” of the MNL likelihood function is organizing the data, as we need to keep track of 3 dimensions (consumer \\(i\\), covariate \\(k\\), and product \\(j\\)) instead of the typical 2 dimensions for cross-sectional regression models (consumer \\(i\\) and covariate \\(k\\)).\nWhat we would like to do is reorganize the data from a “wide” shape with \\(n\\) rows and multiple columns for each covariate, to a “long” shape with \\(n \\times J\\) rows and a single column for each covariate. As part of this re-organization, we’ll add binary variables to indicate the first 3 products; the variables for featured and price are included in the dataset and simply need to be “pivoted” or “melted” from wide to long.\n\n# Melt the product choices, feature status, and prices in one step\nlong_yogurt = pd.wide_to_long(yogurt, stubnames=['y', 'f', 'p'], i='id', j='product', sep='', suffix='\\\\d+')\n\n# Reset index to get a tidy dataframe\nlong_yogurt = long_yogurt.reset_index()\n\n# Rename the columns to match the desired format\nlong_yogurt = long_yogurt.rename(columns={'y': 'choice', 'f': 'featured', 'p': 'price'})\n\n# Create dummy variables for the first three products\nlong_yogurt['yogurt_1'] = (long_yogurt['product'] == 1).astype(int)\nlong_yogurt['yogurt_2'] = (long_yogurt['product'] == 2).astype(int)\nlong_yogurt['yogurt_3'] = (long_yogurt['product'] == 3).astype(int)\n\n# Sort by 'id'\nlong_yogurt = long_yogurt.sort_values(by=['id', 'product']).reset_index(drop=True)\n\n# Drop 'product' column \nlong_yogurt = long_yogurt.drop(columns=['product'])\nlong_yogurt\n\n\n\n\n\n\n\n\n\nid\nchoice\nfeatured\nprice\nyogurt_1\nyogurt_2\nyogurt_3\n\n\n\n\n0\n1\n0\n0\n0.108\n1\n0\n0\n\n\n1\n1\n0\n0\n0.081\n0\n1\n0\n\n\n2\n1\n0\n0\n0.061\n0\n0\n1\n\n\n3\n1\n1\n0\n0.079\n0\n0\n0\n\n\n4\n2\n0\n0\n0.108\n1\n0\n0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n9715\n2429\n1\n0\n0.086\n0\n0\n0\n\n\n9716\n2430\n0\n0\n0.108\n1\n0\n0\n\n\n9717\n2430\n0\n0\n0.086\n0\n1\n0\n\n\n9718\n2430\n0\n0\n0.043\n0\n0\n1\n\n\n9719\n2430\n1\n0\n0.079\n0\n0\n0\n\n\n\n\n9720 rows × 7 columns\n\n\n\n\n\n\n\nEstimation\n\nDefine the log-likelihood function\n\n# Define the log-likelihood function\ndef log_likelihood(beta, X, y):\n    Xbeta = np.dot(X, beta)\n    exp_Xbeta = np.exp(Xbeta)\n    log_likelihood = np.sum(y * Xbeta - np.log(1 + exp_Xbeta))\n    return -log_likelihood\n\n# Define the function to calculate the gradient\ndef gradient(beta, X, y):\n    Xbeta = np.dot(X, beta)\n    exp_Xbeta = np.exp(Xbeta)\n    prob = exp_Xbeta / (1 + exp_Xbeta)\n    gradient = np.dot(X.T, y - prob)\n    return -gradient\n\n\n\nOptimize the log-likelihood function\n\n# Define the variables\nX = long_yogurt[['yogurt_1', 'yogurt_2', 'yogurt_3','featured', 'price']].values\ny = long_yogurt['choice'].values\n\n# Ensure the dependent variable is binary\ny = (y == 1).astype(int)\n\n# Add intercept\nX = np.hstack((np.ones((X.shape[0], 1)), X))\n\n# Initialize beta\ninitial_beta = np.zeros(X.shape[1])\n\n# Optimize the log-likelihood function\nresult = minimize(log_likelihood, initial_beta, args=(X, y), jac=gradient, method='BFGS')\nbeta_hat = result.x\n\nbeta_hat\n\narray([  1.28298667,   1.41787094,   0.90126398,  -3.14053695,\n         0.47140946, -31.97609653])\n\n\n\n\n\n\n\n\nUse MNlogit package to verify the results\n\n\n\n\n\n\nimport statsmodels.api as sm\n# Combine the feature columns into a single matrix X\nX_mn = long_yogurt[['yogurt_1', 'yogurt_2', 'yogurt_3', 'featured', 'price']]\n\n# The dependent variable is the product choice\ny_mn = long_yogurt['choice']\n\n# Fit the multinomial logit model using statsmodels\nX_mn = sm.add_constant(X_mn)  # Add a constant term to the predictors\nmodel = sm.MNLogit(y_mn, X_mn)\nresult_mn = model.fit()\n\n# Display the summary of the model\nresult_mn.summary()\n\nOptimization terminated successfully.\n         Current function value: 0.477971\n         Iterations 7\n\n\n\n\nMNLogit Regression Results\n\n\nDep. Variable:\nchoice\nNo. Observations:\n9720\n\n\nModel:\nMNLogit\nDf Residuals:\n9714\n\n\nMethod:\nMLE\nDf Model:\n5\n\n\nDate:\nWed, 29 May 2024\nPseudo R-squ.:\n0.1500\n\n\nTime:\n15:00:22\nLog-Likelihood:\n-4645.9\n\n\nconverged:\nTrue\nLL-Null:\n-5465.9\n\n\nCovariance Type:\nnonrobust\nLLR p-value:\n0.000\n\n\n\n\n\n\nchoice=1\ncoef\nstd err\nz\nP&gt;|z|\n[0.025\n0.975]\n\n\nconst\n1.2830\n0.173\n7.420\n0.000\n0.944\n1.622\n\n\nyogurt_1\n1.4179\n0.089\n16.008\n0.000\n1.244\n1.591\n\n\nyogurt_2\n0.9013\n0.065\n13.909\n0.000\n0.774\n1.028\n\n\nyogurt_3\n-3.1405\n0.142\n-22.072\n0.000\n-3.419\n-2.862\n\n\nfeatured\n0.4714\n0.119\n3.959\n0.000\n0.238\n0.705\n\n\nprice\n-31.9761\n2.089\n-15.305\n0.000\n-36.071\n-27.881\n\n\n\n\n\n\nResult from manual calculation and MNlogit package calculation is the same.\n\n\n\n\n\n\nDiscussion\nWe learn…\n\nInterpretation:\n\nIntercept (const): 1.2830\n\nThe intercept represents the baseline log-odds of choosing a product when all predictor variables are zero. This is the reference level.\n\nYogurt Type Coefficients:\n\nyogurt_1 (1.4179):\n\nThis positive coefficient indicates that yogurt brand 1 has a higher preference compared to the baseline (yogurt 4).\nThe exponentiated coefficient, exp(1.4179) ≈ 4.13, indicates that the odds of choosing yogurt brand 1 are about 4.13 times higher than the baseline choice.\n\nyogurt_2 (0.9013):\n\nThis positive coefficient indicates that yogurt brand 2 also has a higher preference compared to the yogurt 4.\nThe exponentiated coefficient, exp(0.9013) ≈ 2.46, indicates that the odds of choosing yogurt brand 2 are about 2.46 times higher than the baseline choice.\n\nyogurt_3 (-3.1405):\n\nThis negative coefficient indicates that yogurt brand 3 is less preferred compared to the yogurt 4.\nThe exponentiated coefficient, exp(-3.1405) ≈ 0.04, indicates that the odds of choosing yogurt brand 3 are about 0.04 times (or 96% less) than the baseline choice.\n\n\nPrice (-31.9761):\n\nThis large negative coefficient indicates that as the price of the yogurt increases, the likelihood of choosing that yogurt decreases significantly.\nThe exponentiated coefficient, exp(-31.9761) ≈ 0, shows a very strong aversion to higher prices.\n\nFeatured (0.4714):\n\nThis positive coefficient indicates that if a yogurt is featured, it has a higher preference compared to a non-featured yogurt.\nThe exponentiated coefficient, exp(0.4714) ≈ 1.60, indicates that the odds of choosing a featured yogurt are about 1.60 times higher than a non-featured yogurt.\n\n\n\n\nDollar Benefit Calculation\nNext, use the estimated price coefficient as a dollar-per-util conversion factor to calculate the dollar benefit between the most-preferred yogurt and the least preferred yogurt.\n\nIdentify the coefficients for the most-preferred and least-preferred yogurts:\n\nMost-preferred yogurt: Yogurt 1 (coefficient = 1.4179)\nLeast-preferred yogurt: Yogurt 3 (coefficient = -3.1405)\n\nCalculate the difference in utility:\n\nUtility difference = Coefficient of Yogurt 1 - Coefficient of Yogurt 3\n\nConvert this utility difference to a dollar value using the price coefficient:\n\nPrice coefficient (as dollar-per-util conversion factor): -31.9761\n\nUtility difference:\n\n\\[\n\\text{Utility difference} = 1.4179 - (-3.1405) = 1.4179 + 3.1405 = 4.5584\n\\]\n\nDollar benefit:\n\n\\[\n\\text{Dollar benefit} = \\frac{\\text{Utility difference}}{|\\text{Price coefficient}|} = \\frac{4.5584}{31.9761} \\approx 0.1426\n\\]\nSo, the dollar benefit between the most-preferred yogurt (Yogurt 1) and the least-preferred yogurt (Yogurt 3) is approximately $0.1426 per unit. This means that consumers value Yogurt 1 about $0.1426 more per unit than Yogurt 3.\n\n\nSimulate Counterfactual\nOne benefit of the MNL model is that we can simulate counterfactuals (eg, what if the price of yogurt 1 was $0.10/oz instead of $0.08/oz).\n\n# Predict choice probabilities\npredicted_probs = result_mn.predict(X_mn)\n\n# Calculate current market shares\ncurrent_market_shares = predicted_probs.mean(axis=0)\nprint(\"Current Market Shares:\")\nprint(current_market_shares)\n\n# Increase the price of yogurt 1 by $0.10\nX_mn_new = X_mn.copy()\nX_mn_new.loc[long_yogurt['yogurt_1'] == 1, 'price'] += 0.10\n\n# Predict new choice probabilities with increased price for yogurt 1\npredicted_probs_new = result_mn.predict(X_mn_new)\n\n# Calculate new market shares\nnew_market_shares = predicted_probs_new.mean(axis=0)\nprint(\"New Market Shares after $0.10 price increase for Yogurt 1:\")\nprint(new_market_shares)\n\n# Check if the market share of yogurt 1 decreased\nmarket_share_decrease = current_market_shares[1] - new_market_shares[1]\nprint(\"Change in Market Share for Yogurt 1:\")\nprint(market_share_decrease)\n\nCurrent Market Shares:\n0    0.75\n1    0.25\ndtype: float64\nNew Market Shares after $0.10 price increase for Yogurt 1:\n0    0.828349\n1    0.171651\ndtype: float64\nChange in Market Share for Yogurt 1:\n0.07834917598912244\n\n\nThe market share for yogurt 1 decreased by 0.0784 after the price increase. This indicates that the price sensitivity for yogurt 1 is significant, and consumers are likely to switch to other options when its price increases."
  },
  {
    "objectID": "homeworks/hw3/hw3_questions.html#estimating-minivan-preferences",
    "href": "homeworks/hw3/hw3_questions.html#estimating-minivan-preferences",
    "title": "Multinomial logit (MNL) models",
    "section": "2. Estimating Minivan Preferences",
    "text": "2. Estimating Minivan Preferences\nNow let’s perform a conjoint analysis to estimate consumer preferences for different minivan attributes using a Multinomial Logit (MNL) model. The data consists of responses from a conjoint survey where respondents were presented with various minivan configurations and asked to choose their preferred option. The attributes considered in the analysis include the number of seats, cargo space, engine type, and price.\n\nData\n\nminivan_data = pd.read_csv('./rintro-chapter13conjoint.csv')\nprint(minivan_data.describe()) \n\n# Number of unique respondents\nnum_respondents = minivan_data['resp.id'].nunique()\n\n# Average number of choice tasks per respondent\navg_choice_tasks_per_respondent = minivan_data.groupby('resp.id')['ques'].nunique().mean()\n\n# Number of alternatives per choice task\nalternatives_per_choice_task = minivan_data.groupby(['resp.id', 'ques'])['alt'].nunique().mean()\n\nnum_respondents, avg_choice_tasks_per_respondent, alternatives_per_choice_task\n\n           resp.id         ques          alt         seat        price  \\\ncount  9000.000000  9000.000000  9000.000000  9000.000000  9000.000000   \nmean    100.500000     8.000000     2.000000     6.995444    35.003889   \nstd      57.737513     4.320734     0.816542     0.817005     4.083728   \nmin       1.000000     1.000000     1.000000     6.000000    30.000000   \n25%      50.750000     4.000000     1.000000     6.000000    30.000000   \n50%     100.500000     8.000000     2.000000     7.000000    35.000000   \n75%     150.250000    12.000000     3.000000     8.000000    40.000000   \nmax     200.000000    15.000000     3.000000     8.000000    40.000000   \n\n            choice  \ncount  9000.000000  \nmean      0.333333  \nstd       0.471431  \nmin       0.000000  \n25%       0.000000  \n50%       0.000000  \n75%       1.000000  \nmax       1.000000  \n\n\n(200, 15.0, 3.0)\n\n\n\nNumber of Respondents: 200\nNumber of Choice Tasks per Respondent: 15\nNumber of Alternatives per Choice Task: 3\n\n\nAttributes and Levels:\n\nNumber of seats: 6, 7, 8\nCargo space: 2ft, 3ft\nEngine type: Gas, Hybrid, Electric\nPrice: Various values in thousands of dollars\n\n\n\n\nModel\nNow, estimate a MNL model omitting the following levels to avoide multicollinearity (6 seats, 2ft cargo, and gas engine). Include price as a continuous variable.\n\nimport statsmodels.api as sm\nimport numpy as np\n\n# Convert 'carpool' to binary (0 or 1)\nminivan_data['carpool'] = minivan_data['carpool'].map({'yes': 1, 'no': 0})\n\n# Convert categorical variables to dummy variables\nminivan_dummies = pd.get_dummies(minivan_data, columns=['seat', 'cargo', 'eng']).astype(int)\n\n# Omit seat_6, cargo_2ft, and eng_gas as the reference categories\nindependent_vars = [\n    'seat_7', 'seat_8',   # Seat: 6 is omitted\n    'cargo_3ft',          # Cargo space: 2ft is omitted\n    'eng_hyb', 'eng_elec',# Engine type: gas is omitted\n    'price'               # Price as a continuous variable\n]\n\n# Add a constant to the independent variables\nX = sm.add_constant(minivan_dummies[independent_vars])\ny = minivan_dummies['choice']\n\n# Estimate the MNL model\nmodel = sm.MNLogit(y, X)\nresult = model.fit()\nresult.summary()\n\nOptimization terminated successfully.\n         Current function value: 0.558663\n         Iterations 6\n\n\n\n\nMNLogit Regression Results\n\n\nDep. Variable:\nchoice\nNo. Observations:\n9000\n\n\nModel:\nMNLogit\nDf Residuals:\n8993\n\n\nMethod:\nMLE\nDf Model:\n6\n\n\nDate:\nWed, 29 May 2024\nPseudo R-squ.:\n0.1223\n\n\nTime:\n15:00:23\nLog-Likelihood:\n-5028.0\n\n\nconverged:\nTrue\nLL-Null:\n-5728.6\n\n\nCovariance Type:\nnonrobust\nLLR p-value:\n1.252e-299\n\n\n\n\n\n\nchoice=1\ncoef\nstd err\nz\nP&gt;|z|\n[0.025\n0.975]\n\n\nconst\n5.5322\n0.224\n24.677\n0.000\n5.093\n5.972\n\n\nseat_7\n-0.5248\n0.060\n-8.800\n0.000\n-0.642\n-0.408\n\n\nseat_8\n-0.2931\n0.059\n-5.009\n0.000\n-0.408\n-0.178\n\n\ncargo_3ft\n0.4385\n0.049\n9.004\n0.000\n0.343\n0.534\n\n\neng_hyb\n-0.7605\n0.057\n-13.361\n0.000\n-0.872\n-0.649\n\n\neng_elec\n-1.4347\n0.062\n-23.217\n0.000\n-1.556\n-1.314\n\n\nprice\n-0.1591\n0.006\n-25.616\n0.000\n-0.171\n-0.147\n\n\n\n\n\n\n\n\nResults\n\nInterpretation:\n\nConstant (const): The baseline utility for choosing an alternative.\nNumber of Seats:\n\nseat_7 (-0.5248): Negative coefficient indicates that 7-seat options are less preferred compared to the omitted 6-seat option.\nseat_8 (-0.2931): Negative coefficient indicates that 8-seat options are also less preferred compared to the 6-seat option but to a lesser extent than 7-seat options.\n\nCargo Space (cargo_3ft, 0.4385): Positive coefficient indicates that a 3ft cargo space is more preferred compared to the omitted 2ft option. This suggests respondents value more cargo space.\nEngine Type:\n\neng_hyb (-0.7605): Negative coefficient indicates that hybrid engines are less preferred compared to the omitted gas engine.\neng_elec (-1.4347): Negative coefficient indicates that electric engines are even less preferred compared to the gas engine. This is the most strongly negative coefficient, suggesting a significant preference against electric engines.\n\nPrice (price, -0.1591): Negative coefficient indicates that higher prices reduce the likelihood of an alternative being chosen. This is expected, as higher costs generally deter consumers.\n\n\nPreferred Features:\n\nMore Cargo Space: A 3ft cargo space is preferred over a 2ft cargo space.\nLower Price: Lower prices are preferred.\n\nLess Preferred Features:\n\nNumber of Seats: Both 7-seat and 8-seat options are less preferred compared to 6-seat options, with 7-seat options being the least preferred.\nEngine Type: Hybrid engines are less preferred, and electric engines are significantly less preferred compared to gas engines.\n\n\nBased on the results of the MNL model, we can interpret the price coefficient as a dollar-per-util conversion factor, and we can calculate the dollar value of 3ft of cargo space as compared to 2ft of cargo space.\n\n# Extract coefficients as a dictionary and access the nested dictionary\ncoefficients = result.params.to_dict()[0]\n\n# Calculate the dollar value of 3ft of cargo space compared to 2ft of cargo space\ndollar_value_cargo_3ft = (coefficients['cargo_3ft'] / abs(coefficients['price'])) * 1000\ndollar_value_cargo_3ft \n\n2755.80231518067\n\n\nThe dollar value of having 3ft of cargo space compared to 2ft of cargo space is approximately $2,755.80.\nThis means that respondents value the additional cargo space (3ft vs. 2ft) at around $2,755.80, based on their preferences as reflected in the model.\n\n\nPredict Market Shares\nAssume the market consists of the following 6 minivans. Let’s predict the market shares of each minivan in the market.\n\n\n\nMinivan\nSeats\nCargo\nEngine\nPrice\n\n\n\n\nA\n7\n2\nHyb\n30\n\n\nB\n6\n2\nGas\n30\n\n\nC\n8\n2\nGas\n30\n\n\nD\n7\n3\nGas\n40\n\n\nE\n6\n2\nElec\n40\n\n\nF\n7\n2\nHyb\n35\n\n\n\n\n# Define minivan attributes\nminivan_models = [\n    {'name': 'A', 'seat': 7, 'cargo': 2, 'engine': 'Hyb', 'price': 30, 'seat_7': 1, 'seat_8': 0, 'cargo_3ft': 0, 'eng_hyb': 1, 'eng_elec': 0},\n    {'name': 'B', 'seat': 6, 'cargo': 2, 'engine': 'Gas', 'price': 30, 'seat_7': 0, 'seat_8': 0, 'cargo_3ft': 0, 'eng_hyb': 0, 'eng_elec': 0},\n    {'name': 'C', 'seat': 8, 'cargo': 2, 'engine': 'Gas', 'price': 30, 'seat_7': 0, 'seat_8': 1, 'cargo_3ft': 0, 'eng_hyb': 0, 'eng_elec': 0},\n    {'name': 'D', 'seat': 7, 'cargo': 3, 'engine': 'Gas', 'price': 40, 'seat_7': 1, 'seat_8': 0, 'cargo_3ft': 1, 'eng_hyb': 0, 'eng_elec': 0},\n    {'name': 'E', 'seat': 6, 'cargo': 2, 'engine': 'Elec', 'price': 40, 'seat_7': 0, 'seat_8': 0, 'cargo_3ft': 0, 'eng_hyb': 0, 'eng_elec': 1},\n    {'name': 'F', 'seat': 7, 'cargo': 2, 'engine': 'Hyb', 'price': 35, 'seat_7': 1, 'seat_8': 0, 'cargo_3ft': 0, 'eng_hyb': 1, 'eng_elec': 0}\n]\n\n# Calculate the utility for each minivan\ndef calculate_utility(minivan, coeffs):\n    utility = coeffs['const']\n    utility += coeffs['seat_7'] * minivan['seat_7']\n    utility += coeffs['seat_8'] * minivan['seat_8']\n    utility += coeffs['cargo_3ft'] * minivan['cargo_3ft']\n    utility += coeffs['eng_hyb'] * minivan['eng_hyb']\n    utility += coeffs['eng_elec'] * minivan['eng_elec']\n    utility += coeffs['price'] * minivan['price']\n    return utility\n\n# Calculate utilities\nutilities = [calculate_utility(minivan, coefficients) for minivan in minivan_models]\n\n# Calculate probabilities using the softmax function\nexp_utilities = np.exp(utilities)\nmarket_shares = exp_utilities / np.sum(exp_utilities)\n\n# Combine results with minivan attributes into a DataFrame\nfor minivan, share in zip(minivan_models, market_shares):\n    minivan['market_share'] = share\n\n# Convert to DataFrame\nmarket_share_df = pd.DataFrame(minivan_models)\n\n# Select relevant columns to display\nmarket_share_df = market_share_df[['name', 'seat', 'cargo', 'engine', 'price', 'market_share']]\nmarket_share_df\n\n\n\n\n\n\n\n\n\nname\nseat\ncargo\nengine\nprice\nmarket_share\n\n\n\n\n0\nA\n7\n2\nHyb\n30\n0.116080\n\n\n1\nB\n6\n2\nGas\n30\n0.419692\n\n\n2\nC\n8\n2\nGas\n30\n0.313073\n\n\n3\nD\n7\n3\nGas\n40\n0.078412\n\n\n4\nE\n6\n2\nElec\n40\n0.020359\n\n\n5\nF\n7\n2\nHyb\n35\n0.052385\n\n\n\n\n\n\n\n\n\n\nInterpretation:\n\nMinivan B has the highest predicted market share at 41.97%. This suggests that the basic configuration with a gas engine and lower price is most preferred.\nMinivan C follows with a market share of 31.31%, indicating a significant preference for larger seating capacity despite the same cargo space and engine type.\nMinivan A has a lower market share of 11.61%, reflecting a lower preference for hybrid engines compared to gas engines.\nMinivan D has a market share of 7.84%, indicating that the preference for additional cargo space is outweighed by the higher price.\nMinivan F has a market share of 5.24%, which is less preferred compared to Minivan A due to the higher price.\nMinivan E has the lowest market share of 2.04%, reflecting a significant aversion to electric engines combined with the higher price.\n\nThese results provide insights into consumer preferences, highlighting the importance of lower prices and gas engines over hybrid or electric engines and the preference for standard configurations over premium features.\n\n\n\nConclusion\nThe conjoint analysis of minivan preferences has provided valuable insights into consumer choices and preferences for different minivan attributes. By estimating a Multinomial Logit (MNL) model using survey data, we determined the relative importance of attributes such as the number of seats, cargo space, engine type, and price.\n\nKey Findings:\n\nPrice Sensitivity: Higher prices significantly reduce the likelihood of a minivan being chosen, indicating strong price sensitivity among consumers.\nCargo Space Preference: Consumers show a clear preference for larger cargo space (3ft over 2ft), highlighting the importance of storage capacity.\nEngine Type: Gas engines are preferred over hybrid and electric engines, with electric engines being the least favored.\nSeating Configuration: The 6-seat configuration is the most preferred, with 7-seat and 8-seat options being less favored. This could be due to perceived or actual benefits in space utilization and comfort in smaller seating configurations.\n\n\n\nMarket Share Predictions:\nThe analysis also predicted the market shares for six hypothetical minivan models with varying configurations. The model with a gas engine, 6 seats, and lower price emerged as the most preferred, indicating a potential market advantage for minivans that balance affordability and essential features.\nOverall, the Multinomial Logit (MNL) model has proven to be a robust tool for understanding and quantifying consumer preferences, providing automakers with actionable insights to design and market minivans that better align with consumer desires, thereby enhancing market competitiveness and consumer satisfaction."
  },
  {
    "objectID": "homeworks/hw4/hw4_questions.html",
    "href": "homeworks/hw4/hw4_questions.html",
    "title": "Key Drivers Analysis",
    "section": "",
    "text": "This post implements a few measure of variable importance, interpreted as a key drivers analysis, for certain aspects of a payment card on customer satisfaction with that payment card."
  },
  {
    "objectID": "homeworks/hw4/hw4_questions.html#introduction",
    "href": "homeworks/hw4/hw4_questions.html#introduction",
    "title": "Key Drivers Analysis",
    "section": "Introduction",
    "text": "Introduction\nWe aim to identify and interpret the importance of various features using several metrics: Pearson Correlation, Standardized Regression Coefficients, Usefulness (Incremental R²), Shapley Values for Linear Regression, Johnson’s Relative Weights, Mean Decrease in Gini from Random Forest, and Feature Importance from XGBoost.\nUnderstanding these key drivers will help us to gain insights into which factors most significantly affect customer satisfaction and how different statistical methods can provide unique perspectives on feature importance."
  },
  {
    "objectID": "homeworks/hw4/hw4_questions.html#data-preparation",
    "href": "homeworks/hw4/hw4_questions.html#data-preparation",
    "title": "Key Drivers Analysis",
    "section": "Data Preparation",
    "text": "Data Preparation\n\nimport pandas as pd\n\n# Load the dataset\ndata = pd.read_csv('./data_for_drivers_analysis.csv')\n\n# Describe the dataset\nprint(data.describe())\n\n# Check for missing values \nprint(data.isnull().sum())\n\n             brand            id  satisfaction        trust        build  \\\ncount  2553.000000   2553.000000   2553.000000  2553.000000  2553.000000   \nmean      4.857423   8931.480611      3.386604     0.549550     0.461810   \nstd       2.830096   5114.287849      1.172006     0.497636     0.498637   \nmin       1.000000     88.000000      1.000000     0.000000     0.000000   \n25%       3.000000   4310.000000      3.000000     0.000000     0.000000   \n50%       4.000000   8924.000000      4.000000     1.000000     0.000000   \n75%       6.000000  13545.000000      4.000000     1.000000     1.000000   \nmax      10.000000  18088.000000      5.000000     1.000000     1.000000   \n\n           differs         easy    appealing    rewarding      popular  \\\ncount  2553.000000  2553.000000  2553.000000  2553.000000  2553.000000   \nmean      0.334508     0.536232     0.451234     0.451234     0.536232   \nstd       0.471911     0.498783     0.497714     0.497714     0.498783   \nmin       0.000000     0.000000     0.000000     0.000000     0.000000   \n25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n50%       0.000000     1.000000     0.000000     0.000000     1.000000   \n75%       1.000000     1.000000     1.000000     1.000000     1.000000   \nmax       1.000000     1.000000     1.000000     1.000000     1.000000   \n\n           service       impact  \ncount  2553.000000  2553.000000  \nmean      0.467293     0.330983  \nstd       0.499027     0.470659  \nmin       0.000000     0.000000  \n25%       0.000000     0.000000  \n50%       0.000000     0.000000  \n75%       1.000000     1.000000  \nmax       1.000000     1.000000  \nbrand           0\nid              0\nsatisfaction    0\ntrust           0\nbuild           0\ndiffers         0\neasy            0\nappealing       0\nrewarding       0\npopular         0\nservice         0\nimpact          0\ndtype: int64\n\n\n\nVariables:\n\nbrand: Identifier for the brand.\nid: Identifier for the customer.\nsatisfaction: Customer satisfaction rating.\ntrust: Trust in the brand.\nbuild: Helps build credit quickly.\ndiffers: Is different from other cards.\neasy: Is easy to use.\nappealing: Has appealing benefits or rewards.\nrewarding: Rewards for responsible usage.\npopular: Is used by a lot of people.\nservice: Provides outstanding customer service.\nimpact: Makes a difference in the customer’s life.\n\n\nThe dataset contains various features related to customer satisfaction with a payment card. Each row represents a customer, and each column represents a feature that may influence their satisfaction level. The features include trust, build credit quickly, different from other cards, easy to use, appealing benefits, rewarding for responsible usage, used by many people, outstanding customer service, and making a difference in life.\n\nVisualization\nDistribution of Satisfaction Scores\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nplt.figure(figsize=(10, 6))\nsns.histplot(data['satisfaction'], kde=True, bins=10)\nplt.title('Distribution of Customer Satisfaction')\nplt.xlabel('Satisfaction')\nplt.ylabel('Frequency')\nplt.show()\n\n\n\n\n\n\n\n\nThe histogram shows a relatively normal distribution of satisfaction scores, with the majority of scores clustering around 3 and 4."
  },
  {
    "objectID": "homeworks/hw4/hw4_questions.html#analysis-of-each-metric",
    "href": "homeworks/hw4/hw4_questions.html#analysis-of-each-metric",
    "title": "Key Drivers Analysis",
    "section": "Analysis of Each Metric",
    "text": "Analysis of Each Metric\n\nPearson Correlation\nPearson correlation measures the linear relationship between two variables. It ranges from -1 to 1, where values closer to 1 indicate a strong positive relationship, values closer to -1 indicate a strong negative relationship, and values around 0 indicate no linear relationship.\n\n# Feature selection\nfeatures = ['trust', 'build', 'differs', 'easy', 'appealing', 'rewarding', 'popular', 'service', 'impact']\nX = data[features]\ny = data['satisfaction']\n\n# Calculate Pearson correlations\ncorrelations = data.corr()\npearson_corr = correlations['satisfaction'][features]\n\n# Normalize the correlations\nnormalized_corr = (pearson_corr / pearson_corr.sum()) * 100\nnormalized_corr\n\ntrust        13.283356\nbuild         9.968574\ndiffers       9.600014\neasy         11.064100\nappealing    10.804975\nrewarding    10.107052\npopular       8.905177\nservice      13.044017\nimpact       13.222734\nName: satisfaction, dtype: float64\n\n\nThe Pearson correlation coefficients for each feature with respect to customer satisfaction are calculated to understand which features have the strongest linear relationships with satisfaction.\n\ntrust,impact and service show relatively strong positive correlations with customer satisfaction, indicating that as these factors increase, so does satisfaction.\npopular and differs also have positive correlations but are less strong.\n\n\n\nStandardized Regression Coefficients\nStandardized regression coefficients are used in regression analysis to compare the relative importance of different predictors. They are scaled to have a mean of zero and a standard deviation of one, making them comparable across different units of measurement.\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import StandardScaler\nimport numpy as np\n\n# Standardizing the features\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\n# Fit the linear regression model\nmodel = LinearRegression()\nmodel.fit(X_scaled, y)\n\n# Extract standardized regression coefficients (betas)\nstandardized_coefficients = model.coef_\n\nnormalized_coefficients = (np.abs(standardized_coefficients)/np.abs(standardized_coefficients).sum()) * 100\n\n# Create a DataFrame for better visualization\ncoefficients_df = pd.DataFrame({\n    'Feature': X.columns,\n    'Standardized Coefficient': standardized_coefficients,\n    'Normalized Coefficient': normalized_coefficients\n})\ncoefficients_df\n\n\n\n\n\n\n\n\n\nFeature\nStandardized Coefficient\nNormalized Coefficient\n\n\n\n\n0\ntrust\n0.135635\n25.280109\n\n\n1\nbuild\n0.023411\n4.363461\n\n\n2\ndiffers\n0.032631\n6.081798\n\n\n3\neasy\n0.025744\n4.798205\n\n\n4\nappealing\n0.039647\n7.389479\n\n\n5\nrewarding\n0.005937\n1.106526\n\n\n6\npopular\n0.019470\n3.628859\n\n\n7\nservice\n0.103573\n19.304269\n\n\n8\nimpact\n0.150482\n28.047294\n\n\n\n\n\n\n\n\nThese coefficients indicate how many standard deviations the dependent variable will change per standard deviation increase in the predictor variable.\n\nimpact and trust have the highest standardized coefficients, suggesting they are the most important predictors of customer satisfaction.\nrewarding and popular have relatively low standardized coefficients, indicating they are less influential.\n\n\n\nUsefulness\nUsefulness measures the incremental contribution of each predictor to the R² value of the model. It helps in understanding how much additional variance in the dependent variable is explained by each predictor.\n\n# Full model R-squared\nfull_r2 = model.score(X_scaled, y)\n\n# Calculate usefulness (LMG values)\nusefulness = []\nfor feature in range(X_scaled.shape[1]):\n    X_temp = np.delete(X_scaled, feature, axis=1)\n    temp_model = LinearRegression().fit(X_temp, y)\n    temp_r2 = temp_model.score(X_temp, y)\n    usefulness.append(full_r2 - temp_r2)\n\n# Normalize the usefulness values\nusefulness_normalized = (np.array(usefulness) / sum(usefulness)) * 100\n\n# Create DataFrames for better visualization\nusefulness_df = pd.DataFrame({\n    'Feature': features,\n    'Usefulness Value': usefulness_normalized\n})\n\nusefulness_df\n\n\n\n\n\n\n\n\n\nFeature\nUsefulness Value\n\n\n\n\n0\ntrust\n31.517391\n\n\n1\nbuild\n1.016743\n\n\n2\ndiffers\n2.104285\n\n\n3\neasy\n1.103478\n\n\n4\nappealing\n2.713117\n\n\n5\nrewarding\n0.060194\n\n\n6\npopular\n0.780849\n\n\n7\nservice\n17.869775\n\n\n8\nimpact\n42.834168\n\n\n\n\n\n\n\n\nA higher incremental R² indicates that the predictor adds significant explanatory power to the model.\n\nimpact and trust provide significant explanatory power to the model.\nrewarding and popular have minimal impact on the model’s explanatory power.\n\n\n\nShapley Values for Linear Regression\nShapley values provide a fair distribution of the total gain in model performance among the features. It considers all possible combinations of features and averages the marginal contributions.\n\nSHAP Library: Uses the SHAP library to calculate Shapley values, which is efficient and well-optimized for various machine learning models.\n\n\nimport shap\n# Using the SHAP library's LinearExplainer for Shapley values approximation\nexplainer = shap.LinearExplainer(model, X_scaled)\nshap_values = explainer.shap_values(X_scaled)\n\n# Calculate mean absolute Shapley values for each feature and normalize\nmean_abs_shap_values = np.mean(np.abs(shap_values), axis=0)\nnormalized_shap_values = (mean_abs_shap_values / mean_abs_shap_values.sum()) * 100\n\n# Create a DataFrame for better visualization\nshap_values_df = pd.DataFrame({\n    'Feature': X.columns,\n    'Shapley Value': mean_abs_shap_values,\n    'Normalized Shapley Value': normalized_shap_values\n})\nshap_values_df\n\n\n\n\n\n\n\n\n\nFeature\nShapley Value\nNormalized Shapley Value\n\n\n\n\n0\ntrust\n0.136576\n26.694012\n\n\n1\nbuild\n0.023157\n4.526070\n\n\n2\ndiffers\n0.028857\n5.640139\n\n\n3\neasy\n0.025924\n5.066851\n\n\n4\nappealing\n0.039060\n7.634243\n\n\n5\nrewarding\n0.005861\n1.145452\n\n\n6\npopular\n0.019465\n3.804387\n\n\n7\nservice\n0.102030\n19.941906\n\n\n8\nimpact\n0.130708\n25.546941\n\n\n\n\n\n\n\n\n\nManual Calculation: Implements a manual approach to calculate Shapley values by averaging over permutations, which provides a close approximation to the theoretical Shapley values.\n\n\nimport random\nimport itertools\nfrom sklearn.metrics import r2_score\n\n# Prepare the features matrix X and the target vector y\nX_matrix = X.values\ny_vector = y.values\n\ndef approximate_shapley_values_manual(X, y, n_samples=1000):\n    n_features = X.shape[1]\n    shapley_values = np.zeros(n_features)\n    random.seed(42)\n\n    for i in range(n_features):\n        feature_contributions = []\n        \n        for _ in range(n_samples):\n            # Generate a random subset of features excluding the current feature\n            subset = random.sample([x for x in range(n_features) if x != i], k=random.randint(0, n_features-1))\n            subset_with_i = subset + [i]\n            \n            # Fit model with subset without the feature\n            if subset:\n                scaler_subset = StandardScaler()\n                X_subset = scaler_subset.fit_transform(X[:, subset])\n                model_subset = LinearRegression().fit(X_subset, y)\n                r2_subset = r2_score(y, model_subset.predict(X_subset))\n            else:\n                r2_subset = 0  # baseline R² with no features\n            \n            # Fit model with subset with the feature\n            scaler_subset_with_i = StandardScaler()\n            X_subset_with_i = scaler_subset_with_i.fit_transform(X[:, subset_with_i])\n            model_subset_with_i = LinearRegression().fit(X_subset_with_i, y)\n            r2_subset_with_i = r2_score(y, model_subset_with_i.predict(X_subset_with_i))\n            \n            # Calculate marginal contribution\n            marginal_contribution = r2_subset_with_i - r2_subset\n            feature_contributions.append(marginal_contribution)\n        \n        # Calculate Shapley value for the feature\n        shapley_values[i] = np.mean(feature_contributions)\n\n    return shapley_values\n\n# Calculate approximate Shapley values manually\nshap_values_manual = approximate_shapley_values_manual(X_matrix, y_vector)\n\n# Normalize the Shapley values to sum to 100%\nnormalized_shap_values_manual = (shap_values_manual / shap_values_manual.sum()) * 100\n\n# Map the Shapley values to the feature names and normalize to sum to 100%\nshapley_values_manual_df = pd.DataFrame({'Feature': X.columns, 'Shapley Value': shap_values_manual, 'Normalized Shapley Value': normalized_shap_values_manual})\n\nshapley_values_manual_df\n\n\n\n\n\n\n\n\n\nFeature\nShapley Value\nNormalized Shapley Value\n\n\n\n\n0\ntrust\n0.021209\n19.547288\n\n\n1\nbuild\n0.006640\n6.119831\n\n\n2\ndiffers\n0.006930\n6.386692\n\n\n3\neasy\n0.009254\n8.528979\n\n\n4\nappealing\n0.009916\n9.139131\n\n\n5\nrewarding\n0.007342\n6.767128\n\n\n6\npopular\n0.005680\n5.234813\n\n\n7\nservice\n0.017968\n16.560666\n\n\n8\nimpact\n0.023561\n21.715472\n\n\n\n\n\n\n\n\n\nimpact and trust again emerge as significant contributors to the model.\nrewarding and popular contribute less significantly.\n\n\n\nJohnson’s Relative Weights\nJohnson’s Relative Weights (also known as Johnson’s Epsilon) offer an approximation to Shapley values for linear regression by transforming the predictors into orthogonal components and assessing their contributions.\n\nfrom relativeImp import relativeImp\n# Specify outcome variable\nyName = 'satisfaction'  \n\n# Calculate Johnson's Relative Weights using relativeImp\nrelative_weights = relativeImp(data, outcomeName=yName, driverNames=features)\nrelative_weights\n\n\n\n\n\n\n\n\n\ndriver\nrawRelaImpt\nnormRelaImpt\n\n\n\n\n0\ntrust\n0.021623\n19.835524\n\n\n1\nbuild\n0.007217\n6.620792\n\n\n2\ndiffers\n0.007594\n6.966081\n\n\n3\neasy\n0.008982\n8.239683\n\n\n4\nappealing\n0.009099\n8.346395\n\n\n5\nrewarding\n0.006538\n5.997431\n\n\n6\npopular\n0.005878\n5.392328\n\n\n7\nservice\n0.018134\n16.635164\n\n\n8\nimpact\n0.023946\n21.966601\n\n\n\n\n\n\n\n\nThese weights provide a measure of the relative importance of each feature in the context of a linear model.\n\nimpact and trust have the highest relative weights, confirming their significant role.\nrewarding and popular remain the least important.\n\n\n\nMean Decrease in Gini from Random Forest\nThe Mean Decrease in Gini measures the importance of each feature in reducing the Gini impurity across all trees in the forest. It is specific to tree-based models like Random Forest.\n\nfrom sklearn.ensemble import RandomForestRegressor\n\n# Fit a Random Forest model\nrf_model = RandomForestRegressor(n_estimators=100, random_state=42)\nrf_model.fit(X, y)\n\n# Calculate feature importances using the mean decrease in Gini coefficient\nrf_feature_importances = rf_model.feature_importances_\n\n# Normalize to sum to 100%\nnormalized_rf_feature_importances = (rf_feature_importances / rf_feature_importances.sum()) * 100\n\n# Create a DataFrame for better visualization\nrf_feature_importances_df = pd.DataFrame({\n    'Feature': X.columns,\n    'Mean Decrease in Gini': rf_feature_importances,\n    'Normalized Mean Decrease in Gini': normalized_rf_feature_importances\n})\n\nrf_feature_importances_df\n\n\n\n\n\n\n\n\n\nFeature\nMean Decrease in Gini\nNormalized Mean Decrease in Gini\n\n\n\n\n0\ntrust\n0.155865\n15.586537\n\n\n1\nbuild\n0.102301\n10.230144\n\n\n2\ndiffers\n0.089897\n8.989693\n\n\n3\neasy\n0.099904\n9.990365\n\n\n4\nappealing\n0.085534\n8.553448\n\n\n5\nrewarding\n0.101057\n10.105692\n\n\n6\npopular\n0.094944\n9.494376\n\n\n7\nservice\n0.129664\n12.966365\n\n\n8\nimpact\n0.140834\n14.083380\n\n\n\n\n\n\n\n\nFeatures with a higher Mean Decrease in Gini are more important in reducing impurity and improving model accuracy.\n\ntrust and impact are crucial in reducing Gini impurity, aligning with their high importance in previous metrics.\nservice and build also contribute significantly.\n\n\n\nFeature Importance from XGBoost\nXGBoost provides feature importances based on various metrics like gain, weight, and cover. We use the gain metric, which measures the improvement in accuracy brought by a feature to the branches it is on.\n\nimport xgboost as xgb\n\n# Fit an XGBoost model\nxgb_model = xgb.XGBRegressor(n_estimators=100, random_state=42)\nxgb_model.fit(X, y)\n\n# Get feature importances using the 'gain' metric\nbooster = xgb_model.get_booster()\nimportance_dict = booster.get_score(importance_type='gain')\n\n# Convert the importance dictionary to a DataFrame\nxgb_importance_df = pd.DataFrame(list(importance_dict.items()), columns=['Feature', 'Importance'])\n\n# Normalize to sum to 100%\nxgb_importance_df['Normalized Importance'] = (xgb_importance_df['Importance'] / xgb_importance_df['Importance'].sum()) * 100\n\nxgb_importance_df\n\n\n\n\n\n\n\n\n\nFeature\nImportance\nNormalized Importance\n\n\n\n\n0\ntrust\n0.726525\n28.986719\n\n\n1\nbuild\n0.197839\n7.893330\n\n\n2\ndiffers\n0.141373\n5.640452\n\n\n3\neasy\n0.179203\n7.149780\n\n\n4\nappealing\n0.164887\n6.578636\n\n\n5\nrewarding\n0.163910\n6.539633\n\n\n6\npopular\n0.190827\n7.613552\n\n\n7\nservice\n0.279030\n11.132675\n\n\n8\nimpact\n0.462813\n18.465223\n\n\n\n\n\n\n\n\nFeatures with higher gain contribute more to improving the model’s accuracy. * trust stands out as the most important feature, with a high gain value. * impact and service are also significant contributors."
  },
  {
    "objectID": "homeworks/hw4/hw4_questions.html#combined-analysis-and-conclusion",
    "href": "homeworks/hw4/hw4_questions.html#combined-analysis-and-conclusion",
    "title": "Key Drivers Analysis",
    "section": "Combined Analysis and Conclusion",
    "text": "Combined Analysis and Conclusion\n\nfinal_results = pd.DataFrame({\n    'Feature': features,\n    'Pearson Correlations': normalized_corr.values,\n    'Standardized Regression Coefficient': normalized_coefficients,\n    'Usefulness': usefulness_normalized,\n    'Shapley Values': normalized_shap_values_manual,\n    'Johnson\\'s Weights': relative_weights['normRelaImpt'].values,\n    'Mean Decrease in RF Gini Coefficient': normalized_rf_feature_importances, \n    'XGBoost Feature Importance': xgb_importance_df['Normalized Importance']\n})\n\nfinal_results\n\n\n\n\n\n\n\n\n\nFeature\nPearson Correlations\nStandardized Regression Coefficient\nUsefulness\nShapley Values\nJohnson's Weights\nMean Decrease in RF Gini Coefficient\nXGBoost Feature Importance\n\n\n\n\n0\ntrust\n13.283356\n25.280109\n31.517391\n19.547288\n19.835524\n15.586537\n28.986719\n\n\n1\nbuild\n9.968574\n4.363461\n1.016743\n6.119831\n6.620792\n10.230144\n7.893330\n\n\n2\ndiffers\n9.600014\n6.081798\n2.104285\n6.386692\n6.966081\n8.989693\n5.640452\n\n\n3\neasy\n11.064100\n4.798205\n1.103478\n8.528979\n8.239683\n9.990365\n7.149780\n\n\n4\nappealing\n10.804975\n7.389479\n2.713117\n9.139131\n8.346395\n8.553448\n6.578636\n\n\n5\nrewarding\n10.107052\n1.106526\n0.060194\n6.767128\n5.997431\n10.105692\n6.539633\n\n\n6\npopular\n8.905177\n3.628859\n0.780849\n5.234813\n5.392328\n9.494376\n7.613552\n\n\n7\nservice\n13.044017\n19.304269\n17.869775\n16.560666\n16.635164\n12.966365\n11.132675\n\n\n8\nimpact\n13.222734\n28.047294\n42.834168\n21.715472\n21.966601\n14.083380\n18.465223"
  },
  {
    "objectID": "homeworks/hw4/hw4_questions.html#conclusion",
    "href": "homeworks/hw4/hw4_questions.html#conclusion",
    "title": "Key Drivers Analysis",
    "section": "Conclusion",
    "text": "Conclusion\nIn this analysis, we explored various statistical methods to identify the key drivers of customer satisfaction in a payment card dataset. Each method provides unique insights into feature importance, helping us to understand which factors are most influential. By comparing these methods, we gain a comprehensive view of the factors driving customer satisfaction, enabling better decision-making and targeted improvements.\n\nTrust consistently emerged as a significant driver across all metrics, indicating that building trust with customers is crucial for enhancing their satisfaction.\nImpact was also highlighted as a key factor, suggesting that customers value the positive influence the payment card has on their lives.\nService and Ease of Use were important in several metrics, emphasizing the need for excellent customer service and user-friendly features.\n\nThe combination of these methods provides a robust analysis, allowing us to cross-validate the importance of features and identify the most critical drivers of customer satisfaction. This multi-faceted approach can guide businesses in prioritizing areas for improvement and investment, ultimately leading to higher customer satisfaction and loyalty."
  }
]